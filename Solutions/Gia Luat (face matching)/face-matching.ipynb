{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cc0c718",
   "metadata": {},
   "source": [
    "# B√†i t·∫≠p th·ª±c h√†nh: Nh·∫≠n di·ªán khu√¥n m·∫∑t th·ªùi gian th·ª±c v·ªõi FaceNet & MTCNN tr√™n Webcam\n",
    "\n",
    "## M·ª•c ti√™u:\n",
    "- Th√°o t√°c truy c·∫≠p v√† thu th·∫≠p th√¥ng tin qua webcam b·∫±ng th∆∞ vi·ªán OpenCV\n",
    "- T√≠ch h·ª£p MTCNN ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "- S·ª≠ d·ª•ng FaceNet ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng v√† so s√°nh khu√¥n m·∫∑t theo th·ªùi gian th·ª±c t·ª´ webcam\n",
    "\n",
    "## ƒêi·ªÅu ki·ªán so s√°nh:\n",
    "- N·∫øu **similarity > 0.7**, hi·ªÉn th·ªã \"**Matched**\"\n",
    "- N·∫øu **similarity < 0.7**, hi·ªÉn th·ªã \"**Unknown**\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1af01",
   "metadata": {},
   "source": [
    "## 1. C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4bb369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "# !pip install opencv-python\n",
    "# !pip install mtcnn\n",
    "# !pip install keras-facenet\n",
    "# !pip install tensorflow\n",
    "# !pip install pillow\n",
    "# !pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b043cbdf",
   "metadata": {},
   "source": [
    "## 2. Import c√°c th∆∞ vi·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "print(\"‚úì Import th√†nh c√¥ng t·∫•t c·∫£ th∆∞ vi·ªán!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a618ff3",
   "metadata": {},
   "source": [
    "## 3. Kh·ªüi t·∫°o c√°c model\n",
    "\n",
    "- **MTCNN**: Ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh\n",
    "- **FaceNet**: Tr√≠ch xu·∫•t embedding (vector ƒë·∫∑c tr∆∞ng 512 chi·ªÅu) c·ªßa khu√¥n m·∫∑t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o MTCNN detector\n",
    "print(\"ƒêang kh·ªüi t·∫°o MTCNN detector...\")\n",
    "detector = MTCNN()\n",
    "\n",
    "# Kh·ªüi t·∫°o FaceNet model\n",
    "print(\"ƒêang load FaceNet model...\")\n",
    "facenet_model = FaceNet()\n",
    "\n",
    "print(\"‚úì Kh·ªüi t·∫°o models th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e648b596",
   "metadata": {},
   "source": [
    "## 4. C√°c h√†m ti·ªán √≠ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaef59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(image, box, required_size=(160, 160)):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t khu√¥n m·∫∑t t·ª´ ·∫£nh d·ª±a tr√™n bounding box\n",
    "    \n",
    "    Parameters:\n",
    "        image: ·∫¢nh ƒë·∫ßu v√†o (BGR format)\n",
    "        box: Bounding box t·ª´ MTCNN [x, y, width, height]\n",
    "        required_size: K√≠ch th∆∞·ªõc ƒë·∫ßu ra (160x160 cho FaceNet)\n",
    "    \n",
    "    Returns:\n",
    "        face_array: ·∫¢nh khu√¥n m·∫∑t ƒë√£ ƒë∆∞·ª£c resize v√† chu·∫©n h√≥a\n",
    "    \"\"\"\n",
    "    x1, y1, width, height = box\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    \n",
    "    # Tr√≠ch xu·∫•t khu√¥n m·∫∑t\n",
    "    face = image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n\n",
    "    face_image = Image.fromarray(face)\n",
    "    face_image = face_image.resize(required_size)\n",
    "    face_array = np.asarray(face_image)\n",
    "    \n",
    "    return face_array\n",
    "\n",
    "\n",
    "def get_embedding(facenet_model, face_pixels):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t embedding vector t·ª´ khu√¥n m·∫∑t\n",
    "    \n",
    "    Parameters:\n",
    "        facenet_model: Model FaceNet ƒë√£ load\n",
    "        face_pixels: ·∫¢nh khu√¥n m·∫∑t (160x160x3)\n",
    "    \n",
    "    Returns:\n",
    "        embedding: Vector ƒë·∫∑c tr∆∞ng 512 chi·ªÅu\n",
    "    \"\"\"\n",
    "    # Chu·∫©n h√≥a pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    \n",
    "    # Th√™m batch dimension\n",
    "    samples = np.expand_dims(face_pixels, axis=0)\n",
    "    \n",
    "    # Tr√≠ch xu·∫•t embedding\n",
    "    embedding = facenet_model.embeddings(samples)\n",
    "    \n",
    "    return embedding[0]\n",
    "\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine gi·ªØa 2 embedding vectors\n",
    "    \n",
    "    Parameters:\n",
    "        embedding1, embedding2: C√°c embedding vectors\n",
    "    \n",
    "    Returns:\n",
    "        similarity: Gi√° tr·ªã t·ª´ 0 ƒë·∫øn 1 (c√†ng cao c√†ng gi·ªëng)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "    norm1 = np.linalg.norm(embedding1)\n",
    "    norm2 = np.linalg.norm(embedding2)\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    \n",
    "    # Chuy·ªÉn v·ªÅ kho·∫£ng [0, 1]\n",
    "    similarity = (similarity + 1) / 2\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "\n",
    "def euclidean_distance(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    T√≠nh kho·∫£ng c√°ch Euclidean gi·ªØa 2 embeddings\n",
    "    Sau ƒë√≥ chuy·ªÉn th√†nh similarity score\n",
    "    \"\"\"\n",
    "    distance = np.linalg.norm(embedding1 - embedding2)\n",
    "    # Chuy·ªÉn distance th√†nh similarity (0-1)\n",
    "    # Gi·∫£ s·ª≠ distance th√¥ng th∆∞·ªùng < 1.0 cho c√πng ng∆∞·ªùi\n",
    "    similarity = 1 / (1 + distance)\n",
    "    return similarity\n",
    "\n",
    "print(\"‚úì ƒê√£ ƒë·ªãnh nghƒ©a c√°c h√†m ti·ªán √≠ch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf5b6c",
   "metadata": {},
   "source": [
    "## 5. Thu th·∫≠p ·∫£nh m·∫´u (Reference Images)\n",
    "\n",
    "**B∆∞·ªõc n√†y s·∫Ω:**\n",
    "1. M·ªü webcam\n",
    "2. Thu th·∫≠p 5 ·∫£nh khu√¥n m·∫∑t c·ªßa ng∆∞·ªùi d√πng\n",
    "3. L∆∞u embeddings ƒë·ªÉ so s√°nh sau n√†y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_user_to_database(users_database=None, samples=3):\n",
    "    \"\"\"\n",
    "    Th√™m ng∆∞·ªùi m·ªõi v√†o database hi·ªán c√≥\n",
    "    \n",
    "    Parameters:\n",
    "        users_database: Database hi·ªán t·∫°i (n·∫øu None s·∫Ω load t·ª´ file)\n",
    "        samples: S·ªë ·∫£nh c·∫ßn ch·ª•p cho ng∆∞·ªùi m·ªõi\n",
    "    \n",
    "    Returns:\n",
    "        users_database: Database ƒë√£ c·∫≠p nh·∫≠t\n",
    "    \"\"\"\n",
    "    # Load database n·∫øu ch∆∞a c√≥\n",
    "    if users_database is None:\n",
    "        users_database = load_multi_users_database()\n",
    "        if users_database is None:\n",
    "            users_database = {}\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"TH√äM NG∆Ø·ªúI M·ªöI V√ÄO DATABASE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Nh·∫≠p t√™n\n",
    "    user_name = input(\"Nh·∫≠p t√™n ng∆∞·ªùi m·ªõi: \").strip()\n",
    "    \n",
    "    if not user_name:\n",
    "        print(\"‚ùå T√™n kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng!\")\n",
    "        return users_database\n",
    "    \n",
    "    if user_name in users_database:\n",
    "        print(f\"‚ö† {user_name} ƒë√£ c√≥ trong database!\")\n",
    "        choice = input(\"B·∫°n mu·ªën th√™m ·∫£nh m·ªõi cho ng∆∞·ªùi n√†y? (y/n): \").strip().lower()\n",
    "        if choice != 'y':\n",
    "            return users_database\n",
    "    \n",
    "    # Thu th·∫≠p ·∫£nh\n",
    "    os.makedirs('multi_users', exist_ok=True)\n",
    "    user_folder = os.path.join('multi_users', user_name)\n",
    "    os.makedirs(user_folder, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nüéØ Thu th·∫≠p ·∫£nh cho: {user_name}\")\n",
    "    print(f\"S·∫Ω ch·ª•p {samples} ·∫£nh. Nh·∫•n SPACE ƒë·ªÉ ch·ª•p, ESC ƒë·ªÉ tho√°t.\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    user_embeddings = users_database.get(user_name, [])\n",
    "    captured_count = 0\n",
    "    \n",
    "    while captured_count < samples:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        detections = detector.detect_faces(rgb_frame)\n",
    "        \n",
    "        for detection in detections:\n",
    "            x, y, width, height = detection['box']\n",
    "            cv2.rectangle(display_frame, (x, y), (x+width, y+height), (0, 255, 0), 2)\n",
    "        \n",
    "        status = f\"{user_name} | {captured_count}/{samples} | SPACE ƒë·ªÉ ch·ª•p\"\n",
    "        cv2.putText(display_frame, status, (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow(f'Th√™m ng∆∞·ªùi m·ªõi - {user_name}', display_frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord(' '):\n",
    "            if len(detections) > 0:\n",
    "                box = detections[0]['box']\n",
    "                face = extract_face(rgb_frame, box)\n",
    "                embedding = get_embedding(facenet_model, face)\n",
    "                user_embeddings.append(embedding)\n",
    "                \n",
    "                # L∆∞u ·∫£nh\n",
    "                existing_count = len(glob.glob(f'{user_folder}/*.jpg'))\n",
    "                face_image = Image.fromarray(face)\n",
    "                face_image.save(f'{user_folder}/face_{existing_count+1}.jpg')\n",
    "                \n",
    "                captured_count += 1\n",
    "                print(f\"‚úì ƒê√£ ch·ª•p {captured_count}/{samples}\")\n",
    "            else:\n",
    "                print(\"‚ö† Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t!\")\n",
    "        \n",
    "        elif key == 27:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    if len(user_embeddings) > 0:\n",
    "        users_database[user_name] = user_embeddings\n",
    "        \n",
    "        # L∆∞u l·∫°i database\n",
    "        with open('multi_users_database.pkl', 'wb') as f:\n",
    "            pickle.dump(users_database, f)\n",
    "        \n",
    "        print(f\"\\n‚úì ƒê√£ th√™m {user_name} v·ªõi {len(user_embeddings)} ·∫£nh!\")\n",
    "        print(f\"‚úì Database hi·ªán c√≥ {len(users_database)} ng∆∞·ªùi\")\n",
    "    \n",
    "    return users_database\n",
    "\n",
    "\n",
    "# Th√™m ng∆∞·ªùi m·ªõi\n",
    "# Uncomment ƒë·ªÉ ch·∫°y\n",
    "# users_database = add_new_user_to_database(users_database, samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aceb5c",
   "metadata": {},
   "source": [
    "## 5E. Th√™m ng∆∞·ªùi m·ªõi v√†o database\n",
    "\n",
    "Th√™m ng∆∞·ªùi d√πng m·ªõi m√† kh√¥ng c·∫ßn thu th·∫≠p l·∫°i t·∫•t c·∫£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_multi_users_database():\n",
    "    \"\"\"Hi·ªÉn th·ªã t·∫•t c·∫£ ·∫£nh ƒë√£ thu th·∫≠p\"\"\"\n",
    "    \n",
    "    if not os.path.exists('multi_users'):\n",
    "        print(\"‚ö† Ch∆∞a c√≥ th∆∞ m·ª•c multi_users!\")\n",
    "        return\n",
    "    \n",
    "    users = [d for d in os.listdir('multi_users') if os.path.isdir(os.path.join('multi_users', d))]\n",
    "    \n",
    "    if len(users) == 0:\n",
    "        print(\"‚ö† Kh√¥ng c√≥ ng∆∞·ªùi d√πng n√†o!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"T√¨m th·∫•y {len(users)} ng∆∞·ªùi d√πng\\n\")\n",
    "    \n",
    "    for user_name in users:\n",
    "        user_folder = os.path.join('multi_users', user_name)\n",
    "        images = glob.glob(f'{user_folder}/*.jpg')\n",
    "        \n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üë§ {user_name} - {len(images)} ·∫£nh\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Hi·ªÉn th·ªã ·∫£nh\n",
    "        n_cols = min(len(images), 5)\n",
    "        fig, axes = plt.subplots(1, n_cols, figsize=(n_cols*3, 3))\n",
    "        \n",
    "        if n_cols == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, img_path in enumerate(images[:5]):  # Ch·ªâ hi·ªÉn th·ªã 5 ·∫£nh ƒë·∫ßu\n",
    "            img = plt.imread(img_path)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(f'·∫¢nh {idx+1}')\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'{user_name}', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Hi·ªÉn th·ªã database\n",
    "# Uncomment ƒë·ªÉ ch·∫°y\n",
    "# display_multi_users_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f73988a",
   "metadata": {},
   "source": [
    "## 5D. Hi·ªÉn th·ªã database ƒë√£ thu th·∫≠p\n",
    "\n",
    "Xem t·∫•t c·∫£ ·∫£nh ƒë√£ thu th·∫≠p c·ªßa t·ª´ng ng∆∞·ªùi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd17ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realtime_multi_user_recognition(users_database, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Nh·∫≠n di·ªán nhi·ªÅu ng∆∞·ªùi d√πng th·ªùi gian th·ª±c\n",
    "    \n",
    "    Parameters:\n",
    "        users_database: Dictionary {t√™n: [embeddings]}\n",
    "        threshold: Ng∆∞·ª°ng similarity\n",
    "    \"\"\"\n",
    "    if users_database is None or len(users_database) == 0:\n",
    "        print(\"‚ùå Kh√¥ng c√≥ database ng∆∞·ªùi d√πng!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"NH·∫¨N DI·ªÜN NHI·ªÄU NG∆Ø·ªúI D√ôNG TH·ªúI GIAN TH·ª∞C\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"S·ªë ng∆∞·ªùi trong database: {len(users_database)}\")\n",
    "    print(f\"Ng∆∞·ª°ng similarity: {threshold}\")\n",
    "    print(\"\\nDanh s√°ch ng∆∞·ªùi trong database:\")\n",
    "    for name in users_database.keys():\n",
    "        print(f\"  ‚úì {name}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    frame_count = 0\n",
    "    fps_start_time = time.time()\n",
    "    fps = 0\n",
    "    \n",
    "    # T·∫°o m√†u ng·∫´u nhi√™n cho m·ªói ng∆∞·ªùi\n",
    "    colors = {}\n",
    "    for name in users_database.keys():\n",
    "        colors[name] = tuple(np.random.randint(50, 255, 3).tolist())\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        # T√≠nh FPS\n",
    "        frame_count += 1\n",
    "        if frame_count % 10 == 0:\n",
    "            fps = 10 / (time.time() - fps_start_time)\n",
    "            fps_start_time = time.time()\n",
    "        \n",
    "        # Ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if frame_count % 3 == 0:\n",
    "            detections = detector.detect_faces(rgb_frame)\n",
    "        \n",
    "        # X·ª≠ l√Ω t·ª´ng khu√¥n m·∫∑t\n",
    "        if 'detections' in locals() and len(detections) > 0:\n",
    "            for detection in detections:\n",
    "                box = detection['box']\n",
    "                confidence = detection['confidence']\n",
    "                \n",
    "                if confidence < 0.9:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Tr√≠ch xu·∫•t khu√¥n m·∫∑t v√† embedding\n",
    "                    face = extract_face(rgb_frame, box)\n",
    "                    embedding = get_embedding(facenet_model, face)\n",
    "                    \n",
    "                    # So s√°nh v·ªõi T·∫§T C·∫¢ ng∆∞·ªùi trong database\n",
    "                    best_match_name = \"Unknown\"\n",
    "                    best_similarity = 0\n",
    "                    \n",
    "                    for user_name, user_embeddings in users_database.items():\n",
    "                        for user_emb in user_embeddings:\n",
    "                            sim = cosine_similarity(embedding, user_emb)\n",
    "                            if sim > best_similarity:\n",
    "                                best_similarity = sim\n",
    "                                best_match_name = user_name\n",
    "                    \n",
    "                    # X√°c ƒë·ªãnh matched hay unknown\n",
    "                    if best_similarity > threshold:\n",
    "                        label = best_match_name\n",
    "                        color = colors.get(best_match_name, (0, 255, 0))\n",
    "                        status = \"‚úì\"\n",
    "                    else:\n",
    "                        label = \"Unknown\"\n",
    "                        color = (0, 0, 255)  # ƒê·ªè\n",
    "                        status = \"‚úó\"\n",
    "                    \n",
    "                    # V·∫Ω bounding box\n",
    "                    x, y, width, height = box\n",
    "                    cv2.rectangle(display_frame, (x, y), (x+width, y+height), color, 3)\n",
    "                    \n",
    "                    # V·∫Ω label\n",
    "                    label_text = f\"{status} {label}\"\n",
    "                    similarity_text = f\"Sim: {best_similarity:.3f}\"\n",
    "                    \n",
    "                    # Background cho text\n",
    "                    (text_width, text_height), _ = cv2.getTextSize(\n",
    "                        label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)\n",
    "                    cv2.rectangle(display_frame, (x, y - text_height - 15), \n",
    "                                (x + text_width + 10, y), color, -1)\n",
    "                    \n",
    "                    # Text ch√≠nh\n",
    "                    cv2.putText(display_frame, label_text, (x + 5, y - 5),\n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "                    \n",
    "                    # Similarity score\n",
    "                    cv2.putText(display_frame, similarity_text, (x, y + height + 25),\n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö† L·ªói: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # Hi·ªÉn th·ªã th√¥ng tin\n",
    "        info_text = f\"FPS: {fps:.1f} | Users: {len(users_database)} | Threshold: {threshold}\"\n",
    "        cv2.putText(display_frame, info_text, (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Hi·ªÉn th·ªã danh s√°ch ng∆∞·ªùi\n",
    "        y_offset = 60\n",
    "        for idx, name in enumerate(list(users_database.keys())[:5]):  # Ch·ªâ hi·ªÉn th·ªã 5 ng∆∞·ªùi ƒë·∫ßu\n",
    "            text = f\"{idx+1}. {name}\"\n",
    "            cv2.putText(display_frame, text, (10, y_offset),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors.get(name, (255, 255, 255)), 2)\n",
    "            y_offset += 25\n",
    "        \n",
    "        cv2.imshow('Multi-User Face Recognition', display_frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q') or key == 27:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"\\n‚úì ƒê√£ d·ª´ng ch∆∞∆°ng tr√¨nh!\")\n",
    "\n",
    "\n",
    "# Ch·∫°y nh·∫≠n di·ªán nhi·ªÅu ng∆∞·ªùi\n",
    "# Uncomment ƒë·ªÉ ch·∫°y\n",
    "# if 'users_database' in locals() and users_database is not None:\n",
    "#     realtime_multi_user_recognition(users_database, threshold=0.7)\n",
    "# else:\n",
    "#     print(\"‚ùå Vui l√≤ng load ho·∫∑c thu th·∫≠p database tr∆∞·ªõc!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd4b2fb",
   "metadata": {},
   "source": [
    "## 5C. Nh·∫≠n di·ªán v·ªõi nhi·ªÅu ng∆∞·ªùi d√πng\n",
    "\n",
    "Nh·∫≠n di·ªán khu√¥n m·∫∑t th·ªùi gian th·ª±c v√† hi·ªÉn th·ªã t√™n ng∆∞·ªùi ƒë∆∞·ª£c nh·∫≠n di·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f67d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multi_users_database():\n",
    "    \"\"\"Load database nhi·ªÅu ng∆∞·ªùi t·ª´ file\"\"\"\n",
    "    try:\n",
    "        with open('multi_users_database.pkl', 'rb') as f:\n",
    "            users_db = pickle.load(f)\n",
    "        print(f\"‚úì ƒê√£ load database v·ªõi {len(users_db)} ng∆∞·ªùi:\")\n",
    "        for name, embeddings in users_db.items():\n",
    "            print(f\"  - {name}: {len(embeddings)} ·∫£nh\")\n",
    "        return users_db\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö† Ch∆∞a c√≥ file database. Vui l√≤ng ch·∫°y cell thu th·∫≠p tr∆∞·ªõc.\")\n",
    "        return None\n",
    "\n",
    "# Uncomment ƒë·ªÉ load database\n",
    "# users_database = load_multi_users_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe445a2a",
   "metadata": {},
   "source": [
    "## 5B. Load database nhi·ªÅu ng∆∞·ªùi ƒë√£ l∆∞u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599208c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_multiple_users(num_users=5, samples_per_user=3):\n",
    "    \"\"\"\n",
    "    Thu th·∫≠p ·∫£nh khu√¥n m·∫∑t c·ªßa nhi·ªÅu ng∆∞·ªùi d√πng kh√°c nhau\n",
    "    \n",
    "    Parameters:\n",
    "        num_users: S·ªë l∆∞·ª£ng ng∆∞·ªùi d√πng c·∫ßn thu th·∫≠p\n",
    "        samples_per_user: S·ªë ·∫£nh m·ªói ng∆∞·ªùi (m·∫∑c ƒë·ªãnh 3)\n",
    "    \n",
    "    Returns:\n",
    "        users_database: Dictionary ch·ª©a {t√™n: [embeddings]}\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"THU TH·∫¨P ·∫¢NH C·ª¶A NHI·ªÄU NG∆Ø·ªúI D√ôNG\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"S·∫Ω thu th·∫≠p ·∫£nh c·ªßa {num_users} ng∆∞·ªùi, m·ªói ng∆∞·ªùi {samples_per_user} ·∫£nh\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    users_database = {}\n",
    "    \n",
    "    # T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh\n",
    "    os.makedirs('multi_users', exist_ok=True)\n",
    "    \n",
    "    for user_idx in range(num_users):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"NG∆Ø·ªúI TH·ª© {user_idx + 1}/{num_users}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Nh·∫≠p t√™n ng∆∞·ªùi d√πng\n",
    "        user_name = input(f\"Nh·∫≠p t√™n ng∆∞·ªùi th·ª© {user_idx + 1} (ho·∫∑c 'skip' ƒë·ªÉ b·ªè qua): \").strip()\n",
    "        \n",
    "        if user_name.lower() == 'skip':\n",
    "            print(\"‚è≠ ƒê√£ b·ªè qua ng∆∞·ªùi n√†y.\")\n",
    "            continue\n",
    "        \n",
    "        if not user_name:\n",
    "            user_name = f\"User_{user_idx + 1}\"\n",
    "            print(f\"‚ö† Kh√¥ng nh·∫≠p t√™n. S·ª≠ d·ª•ng t√™n m·∫∑c ƒë·ªãnh: {user_name}\")\n",
    "        \n",
    "        # T·∫°o th∆∞ m·ª•c cho ng∆∞·ªùi n√†y\n",
    "        user_folder = os.path.join('multi_users', user_name)\n",
    "        os.makedirs(user_folder, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\nüéØ Thu th·∫≠p ·∫£nh cho: {user_name}\")\n",
    "        print(\"H∆∞·ªõng d·∫´n:\")\n",
    "        print(\"  - Ng∆∞·ªùi n√†y h√£y nh√¨n v√†o camera\")\n",
    "        print(\"  - Nh·∫•n SPACE ƒë·ªÉ ch·ª•p ·∫£nh\")\n",
    "        print(\"  - Nh·∫•n ESC ƒë·ªÉ ho√†n th√†nh s·ªõm\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)\n",
    "        user_embeddings = []\n",
    "        captured_count = 0\n",
    "        \n",
    "        while captured_count < samples_per_user:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Kh√¥ng th·ªÉ truy c·∫≠p webcam!\")\n",
    "                break\n",
    "            \n",
    "            # Flip frame\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            display_frame = frame.copy()\n",
    "            \n",
    "            # Ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            detections = detector.detect_faces(rgb_frame)\n",
    "            \n",
    "            # V·∫Ω bounding box\n",
    "            for detection in detections:\n",
    "                x, y, width, height = detection['box']\n",
    "                confidence = detection['confidence']\n",
    "                \n",
    "                cv2.rectangle(display_frame, (x, y), (x+width, y+height), (0, 255, 0), 2)\n",
    "                cv2.putText(display_frame, f'Conf: {confidence:.2f}', \n",
    "                           (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "            \n",
    "            # Hi·ªÉn th·ªã th√¥ng tin\n",
    "            info_text = f\"Thu th·∫≠p cho: {user_name}\"\n",
    "            cv2.putText(display_frame, info_text, (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "            \n",
    "            status_text = f\"ƒê√£ ch·ª•p: {captured_count}/{samples_per_user} | Nh·∫•n SPACE\"\n",
    "            cv2.putText(display_frame, status_text, (10, 60), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            cv2.imshow(f'Thu th·∫≠p ·∫£nh - {user_name}', display_frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            # Nh·∫•n SPACE ƒë·ªÉ ch·ª•p\n",
    "            if key == ord(' '):\n",
    "                if len(detections) > 0:\n",
    "                    detection = detections[0]\n",
    "                    box = detection['box']\n",
    "                    \n",
    "                    # Tr√≠ch xu·∫•t khu√¥n m·∫∑t\n",
    "                    face = extract_face(rgb_frame, box)\n",
    "                    \n",
    "                    # Tr√≠ch xu·∫•t embedding\n",
    "                    embedding = get_embedding(facenet_model, face)\n",
    "                    user_embeddings.append(embedding)\n",
    "                    \n",
    "                    # L∆∞u ·∫£nh\n",
    "                    face_image = Image.fromarray(face)\n",
    "                    face_image.save(f'{user_folder}/face_{captured_count+1}.jpg')\n",
    "                    \n",
    "                    captured_count += 1\n",
    "                    print(f\"‚úì ƒê√£ ch·ª•p ·∫£nh {captured_count}/{samples_per_user} cho {user_name}\")\n",
    "                else:\n",
    "                    print(\"‚ö† Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t!\")\n",
    "            \n",
    "            # Nh·∫•n ESC ƒë·ªÉ ho√†n th√†nh s·ªõm\n",
    "            elif key == 27:\n",
    "                print(f\"‚è≠ Ho√†n th√†nh s·ªõm cho {user_name}\")\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # L∆∞u embeddings c·ªßa ng∆∞·ªùi n√†y\n",
    "        if len(user_embeddings) > 0:\n",
    "            users_database[user_name] = user_embeddings\n",
    "            print(f\"‚úì ƒê√£ l∆∞u {len(user_embeddings)} ·∫£nh cho {user_name}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Kh√¥ng thu th·∫≠p ƒë∆∞·ª£c ·∫£nh n√†o cho {user_name}\")\n",
    "        \n",
    "        # Ngh·ªâ 1 gi√¢y tr∆∞·ªõc khi chuy·ªÉn ng∆∞·ªùi ti·∫øp theo\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # L∆∞u database\n",
    "    if len(users_database) > 0:\n",
    "        with open('multi_users_database.pkl', 'wb') as f:\n",
    "            pickle.dump(users_database, f)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"‚úì HO√ÄN TH√ÄNH THU TH·∫¨P!\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"T·ªïng s·ªë ng∆∞·ªùi ƒë√£ thu th·∫≠p: {len(users_database)}\")\n",
    "        for name, embeddings in users_database.items():\n",
    "            print(f\"  - {name}: {len(embeddings)} ·∫£nh\")\n",
    "        print(f\"‚úì ƒê√£ l∆∞u database v√†o 'multi_users_database.pkl'\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Kh√¥ng thu th·∫≠p ƒë∆∞·ª£c d·ªØ li·ªáu!\")\n",
    "    \n",
    "    return users_database\n",
    "\n",
    "\n",
    "# Ch·∫°y h√†m thu th·∫≠p nhi·ªÅu ng∆∞·ªùi\n",
    "# Uncomment d√≤ng d∆∞·ªõi ƒë·ªÉ ch·∫°y\n",
    "# users_database = collect_multiple_users(num_users=5, samples_per_user=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de65a57",
   "metadata": {},
   "source": [
    "## 5A. Thu th·∫≠p ·∫£nh c·ªßa NHI·ªÄU NG∆Ø·ªúI D√ôNG\n",
    "\n",
    "**Phi√™n b·∫£n n√¢ng cao - Thu th·∫≠p ·∫£nh c·ªßa nhi·ªÅu ng∆∞·ªùi:**\n",
    "- C√≥ th·ªÉ ch·ª•p ·∫£nh c·ªßa 5 ng∆∞·ªùi kh√°c nhau (ho·∫∑c nhi·ªÅu h∆°n)\n",
    "- M·ªói ng∆∞·ªùi c√≥ t√™n ri√™ng\n",
    "- M·ªói ng∆∞·ªùi c√≥ th·ªÉ c√≥ nhi·ªÅu ·∫£nh tham chi·∫øu\n",
    "- H·ªá th·ªëng s·∫Ω nh·∫≠n di·ªán v√† hi·ªÉn th·ªã t√™n ng∆∞·ªùi ƒë√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_reference_faces(num_samples=5):\n",
    "    \"\"\"\n",
    "    Thu th·∫≠p ·∫£nh khu√¥n m·∫∑t tham chi·∫øu t·ª´ webcam\n",
    "    \n",
    "    Parameters:\n",
    "        num_samples: S·ªë l∆∞·ª£ng ·∫£nh c·∫ßn thu th·∫≠p\n",
    "    \n",
    "    Returns:\n",
    "        reference_embeddings: Danh s√°ch c√°c embeddings tham chi·∫øu\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"B∆Ø·ªöC 1: THU TH·∫¨P ·∫¢NH THAM CHI·∫æU\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"S·∫Ω thu th·∫≠p {num_samples} ·∫£nh khu√¥n m·∫∑t c·ªßa b·∫°n\")\n",
    "    print(\"H∆∞·ªõng d·∫´n:\")\n",
    "    print(\"  - Nh√¨n th·∫≥ng v√†o camera\")\n",
    "    print(\"  - Gi·ªØ khu√¥n m·∫∑t trong khung h√¨nh\")\n",
    "    print(\"  - Nh·∫•n SPACE ƒë·ªÉ ch·ª•p ·∫£nh\")\n",
    "    print(\"  - Nh·∫•n ESC ƒë·ªÉ tho√°t\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    reference_embeddings = []\n",
    "    captured_count = 0\n",
    "    \n",
    "    # T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh n·∫øu ch∆∞a c√≥\n",
    "    os.makedirs('reference_faces', exist_ok=True)\n",
    "    \n",
    "    while captured_count < num_samples:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"‚ùå Kh√¥ng th·ªÉ truy c·∫≠p webcam!\")\n",
    "            break\n",
    "        \n",
    "        # Flip frame ƒë·ªÉ d·ªÖ nh√¨n\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        # Ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        detections = detector.detect_faces(rgb_frame)\n",
    "        \n",
    "        # V·∫Ω bounding box\n",
    "        for detection in detections:\n",
    "            x, y, width, height = detection['box']\n",
    "            confidence = detection['confidence']\n",
    "            \n",
    "            # V·∫Ω khung\n",
    "            cv2.rectangle(display_frame, (x, y), (x+width, y+height), (0, 255, 0), 2)\n",
    "            cv2.putText(display_frame, f'Confidence: {confidence:.2f}', \n",
    "                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        # Hi·ªÉn th·ªã tr·∫°ng th√°i\n",
    "        status_text = f\"ƒê√£ ch·ª•p: {captured_count}/{num_samples} | Nh·∫•n SPACE ƒë·ªÉ ch·ª•p\"\n",
    "        cv2.putText(display_frame, status_text, (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Thu th·∫≠p ·∫£nh tham chi·∫øu', display_frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        # Nh·∫•n SPACE ƒë·ªÉ ch·ª•p\n",
    "        if key == ord(' '):\n",
    "            if len(detections) > 0:\n",
    "                detection = detections[0]  # L·∫•y khu√¥n m·∫∑t ƒë·∫ßu ti√™n\n",
    "                box = detection['box']\n",
    "                \n",
    "                # Tr√≠ch xu·∫•t khu√¥n m·∫∑t\n",
    "                face = extract_face(rgb_frame, box)\n",
    "                \n",
    "                # Tr√≠ch xu·∫•t embedding\n",
    "                embedding = get_embedding(facenet_model, face)\n",
    "                reference_embeddings.append(embedding)\n",
    "                \n",
    "                # L∆∞u ·∫£nh\n",
    "                face_image = Image.fromarray(face)\n",
    "                face_image.save(f'reference_faces/face_{captured_count+1}.jpg')\n",
    "                \n",
    "                captured_count += 1\n",
    "                print(f\"‚úì ƒê√£ ch·ª•p ·∫£nh {captured_count}/{num_samples}\")\n",
    "            else:\n",
    "                print(\"‚ö† Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t! Th·ª≠ l·∫°i.\")\n",
    "        \n",
    "        # Nh·∫•n ESC ƒë·ªÉ tho√°t\n",
    "        elif key == 27:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    if len(reference_embeddings) > 0:\n",
    "        print(f\"\\n‚úì Ho√†n th√†nh! ƒê√£ thu th·∫≠p {len(reference_embeddings)} ·∫£nh tham chi·∫øu\")\n",
    "        \n",
    "        # L∆∞u embeddings\n",
    "        with open('reference_embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(reference_embeddings, f)\n",
    "        print(\"‚úì ƒê√£ l∆∞u embeddings v√†o file 'reference_embeddings.pkl'\")\n",
    "    else:\n",
    "        print(\"‚ùå Kh√¥ng thu th·∫≠p ƒë∆∞·ª£c ·∫£nh n√†o!\")\n",
    "    \n",
    "    return reference_embeddings\n",
    "\n",
    "\n",
    "# Ch·∫°y h√†m thu th·∫≠p ·∫£nh tham chi·∫øu\n",
    "reference_embeddings = collect_reference_faces(num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0035a",
   "metadata": {},
   "source": [
    "## 6. Load embeddings ƒë√£ l∆∞u (N·∫øu ƒë√£ c√≥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1649f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings t·ª´ file n·∫øu ƒë√£ c√≥\n",
    "def load_reference_embeddings():\n",
    "    \"\"\"Load embeddings ƒë√£ l∆∞u t·ª´ file\"\"\"\n",
    "    try:\n",
    "        with open('reference_embeddings.pkl', 'rb') as f:\n",
    "            embeddings = pickle.load(f)\n",
    "        print(f\"‚úì ƒê√£ load {len(embeddings)} reference embeddings t·ª´ file\")\n",
    "        return embeddings\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö† Ch∆∞a c√≥ file reference embeddings. Vui l√≤ng ch·∫°y cell thu th·∫≠p ·∫£nh tr∆∞·ªõc.\")\n",
    "        return None\n",
    "\n",
    "# Uncomment d√≤ng d∆∞·ªõi n·∫øu mu·ªën load embeddings ƒë√£ l∆∞u\n",
    "# reference_embeddings = load_reference_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d73de32",
   "metadata": {},
   "source": [
    "## 7. Nh·∫≠n di·ªán khu√¥n m·∫∑t th·ªùi gian th·ª±c\n",
    "\n",
    "**Ch∆∞∆°ng tr√¨nh s·∫Ω:**\n",
    "1. M·ªü webcam li√™n t·ª•c\n",
    "2. Ph√°t hi·ªán khu√¥n m·∫∑t b·∫±ng MTCNN\n",
    "3. Tr√≠ch xu·∫•t embedding b·∫±ng FaceNet\n",
    "4. So s√°nh v·ªõi embeddings tham chi·∫øu\n",
    "5. Hi·ªÉn th·ªã k·∫øt qu·∫£:\n",
    "   - **Matched** (m√†u xanh) n·∫øu similarity > 0.7\n",
    "   - **Unknown** (m√†u ƒë·ªè) n·∫øu similarity < 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28413425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realtime_face_recognition(reference_embeddings, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Nh·∫≠n di·ªán khu√¥n m·∫∑t th·ªùi gian th·ª±c\n",
    "    \n",
    "    Parameters:\n",
    "        reference_embeddings: Danh s√°ch embeddings tham chi·∫øu\n",
    "        threshold: Ng∆∞·ª°ng similarity (0.7 theo y√™u c·∫ßu)\n",
    "    \"\"\"\n",
    "    if reference_embeddings is None or len(reference_embeddings) == 0:\n",
    "        print(\"‚ùå Kh√¥ng c√≥ reference embeddings! Vui l√≤ng ch·∫°y cell thu th·∫≠p ·∫£nh tr∆∞·ªõc.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"B∆Ø·ªöC 2: NH·∫¨N DI·ªÜN KHU√îN M·∫∂T TH·ªúI GIAN TH·ª∞C\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Ng∆∞·ª°ng similarity: {threshold}\")\n",
    "    print(\"H∆∞·ªõng d·∫´n:\")\n",
    "    print(\"  - Nh√¨n v√†o camera ƒë·ªÉ nh·∫≠n di·ªán\")\n",
    "    print(\"  - Nh·∫•n 'q' ho·∫∑c ESC ƒë·ªÉ tho√°t\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # ƒê·∫∑t resolution cao h∆°n\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    frame_count = 0\n",
    "    fps_start_time = time.time()\n",
    "    fps = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ webcam!\")\n",
    "            break\n",
    "        \n",
    "        # Flip frame\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        # T√≠nh FPS\n",
    "        frame_count += 1\n",
    "        if frame_count % 10 == 0:\n",
    "            fps = 10 / (time.time() - fps_start_time)\n",
    "            fps_start_time = time.time()\n",
    "        \n",
    "        # Convert sang RGB cho MTCNN\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Ph√°t hi·ªán khu√¥n m·∫∑t (ch·ªâ x·ª≠ l√Ω m·ªói 3 frames ƒë·ªÉ tƒÉng t·ªëc)\n",
    "        if frame_count % 3 == 0:\n",
    "            detections = detector.detect_faces(rgb_frame)\n",
    "        \n",
    "        # X·ª≠ l√Ω t·ª´ng khu√¥n m·∫∑t ph√°t hi·ªán ƒë∆∞·ª£c\n",
    "        if 'detections' in locals() and len(detections) > 0:\n",
    "            for detection in detections:\n",
    "                box = detection['box']\n",
    "                confidence = detection['confidence']\n",
    "                keypoints = detection['keypoints']\n",
    "                \n",
    "                # Ch·ªâ x·ª≠ l√Ω n·∫øu confidence > 0.9\n",
    "                if confidence < 0.9:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Tr√≠ch xu·∫•t khu√¥n m·∫∑t\n",
    "                    face = extract_face(rgb_frame, box)\n",
    "                    \n",
    "                    # Tr√≠ch xu·∫•t embedding\n",
    "                    embedding = get_embedding(facenet_model, face)\n",
    "                    \n",
    "                    # So s√°nh v·ªõi t·∫•t c·∫£ reference embeddings\n",
    "                    similarities = []\n",
    "                    for ref_emb in reference_embeddings:\n",
    "                        sim = cosine_similarity(embedding, ref_emb)\n",
    "                        similarities.append(sim)\n",
    "                    \n",
    "                    # L·∫•y similarity cao nh·∫•t\n",
    "                    max_similarity = max(similarities)\n",
    "                    \n",
    "                    # X√°c ƒë·ªãnh matched hay unknown\n",
    "                    if max_similarity > threshold:\n",
    "                        label = \"Matched\"\n",
    "                        color = (0, 255, 0)  # Xanh l√°\n",
    "                        status = \"‚úì\"\n",
    "                    else:\n",
    "                        label = \"Unknown\"\n",
    "                        color = (0, 0, 255)  # ƒê·ªè\n",
    "                        status = \"‚úó\"\n",
    "                    \n",
    "                    # V·∫Ω bounding box\n",
    "                    x, y, width, height = box\n",
    "                    cv2.rectangle(display_frame, (x, y), (x+width, y+height), color, 3)\n",
    "                    \n",
    "                    # V·∫Ω background cho text\n",
    "                    label_text = f\"{status} {label}\"\n",
    "                    similarity_text = f\"Similarity: {max_similarity:.3f}\"\n",
    "                    \n",
    "                    # Label ch√≠nh\n",
    "                    (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                        label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)\n",
    "                    cv2.rectangle(display_frame, (x, y - text_height - 15), \n",
    "                                (x + text_width + 10, y), color, -1)\n",
    "                    cv2.putText(display_frame, label_text, (x + 5, y - 5),\n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "                    \n",
    "                    # Similarity score\n",
    "                    cv2.putText(display_frame, similarity_text, (x, y + height + 25),\n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                    \n",
    "                    # V·∫Ω keypoints (m·∫Øt, m≈©i, mi·ªáng)\n",
    "                    for key, point in keypoints.items():\n",
    "                        cv2.circle(display_frame, point, 3, (255, 255, 0), -1)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö† L·ªói x·ª≠ l√Ω khu√¥n m·∫∑t: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # Hi·ªÉn th·ªã th√¥ng tin\n",
    "        info_text = f\"FPS: {fps:.1f} | Threshold: {threshold} | Nh·∫•n 'q' ƒë·ªÉ tho√°t\"\n",
    "        cv2.putText(display_frame, info_text, (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # V·∫Ω h∆∞·ªõng d·∫´n\n",
    "        guide_text = \"Matched (>0.7) | Unknown (<0.7)\"\n",
    "        cv2.putText(display_frame, guide_text, (10, display_frame.shape[0] - 15),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)\n",
    "        \n",
    "        # Hi·ªÉn th·ªã frame\n",
    "        cv2.imshow('Face Recognition - FaceNet & MTCNN', display_frame)\n",
    "        \n",
    "        # Tho√°t khi nh·∫•n 'q' ho·∫∑c ESC\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q') or key == 27:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"\\n‚úì ƒê√£ d·ª´ng ch∆∞∆°ng tr√¨nh nh·∫≠n di·ªán!\")\n",
    "\n",
    "\n",
    "# Ch·∫°y ch∆∞∆°ng tr√¨nh nh·∫≠n di·ªán th·ªùi gian th·ª±c\n",
    "if 'reference_embeddings' in locals() and reference_embeddings is not None:\n",
    "    realtime_face_recognition(reference_embeddings, threshold=0.7)\n",
    "else:\n",
    "    print(\"‚ùå Vui l√≤ng ch·∫°y cell thu th·∫≠p ·∫£nh tham chi·∫øu tr∆∞·ªõc!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb47c86",
   "metadata": {},
   "source": [
    "## 8. Ki·ªÉm tra v√† ƒë√°nh gi√°\n",
    "\n",
    "Hi·ªÉn th·ªã c√°c ·∫£nh tham chi·∫øu ƒë√£ thu th·∫≠p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Hi·ªÉn th·ªã c√°c ·∫£nh tham chi·∫øu\n",
    "reference_images = glob.glob('reference_faces/*.jpg')\n",
    "\n",
    "if len(reference_images) > 0:\n",
    "    fig, axes = plt.subplots(1, len(reference_images), figsize=(15, 3))\n",
    "    \n",
    "    if len(reference_images) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, img_path in enumerate(reference_images):\n",
    "        img = plt.imread(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f'Reference {idx+1}')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('·∫¢nh tham chi·∫øu ƒë√£ thu th·∫≠p', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úì ƒê√£ hi·ªÉn th·ªã {len(reference_images)} ·∫£nh tham chi·∫øu\")\n",
    "else:\n",
    "    print(\"‚ö† Ch∆∞a c√≥ ·∫£nh tham chi·∫øu. Vui l√≤ng ch·∫°y cell thu th·∫≠p ·∫£nh.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6c791",
   "metadata": {},
   "source": [
    "## 9. Test v·ªõi ·∫£nh tƒ©nh (Optional)\n",
    "\n",
    "Test nh·∫≠n di·ªán v·ªõi m·ªôt ·∫£nh c·ª• th·ªÉ thay v√¨ webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a10713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_image(image_path, reference_embeddings, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Test nh·∫≠n di·ªán v·ªõi m·ªôt ·∫£nh c·ª• th·ªÉ\n",
    "    \n",
    "    Parameters:\n",
    "        image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh c·∫ßn test\n",
    "        reference_embeddings: Danh s√°ch embeddings tham chi·∫øu\n",
    "        threshold: Ng∆∞·ª°ng similarity\n",
    "    \"\"\"\n",
    "    if reference_embeddings is None or len(reference_embeddings) == 0:\n",
    "        print(\"‚ùå Kh√¥ng c√≥ reference embeddings!\")\n",
    "        return\n",
    "    \n",
    "    # ƒê·ªçc ·∫£nh\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "    detections = detector.detect_faces(rgb_image)\n",
    "    \n",
    "    if len(detections) == 0:\n",
    "        print(\"‚ö† Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh!\")\n",
    "        return\n",
    "    \n",
    "    # X·ª≠ l√Ω khu√¥n m·∫∑t ƒë·∫ßu ti√™n\n",
    "    detection = detections[0]\n",
    "    box = detection['box']\n",
    "    \n",
    "    # Tr√≠ch xu·∫•t khu√¥n m·∫∑t v√† embedding\n",
    "    face = extract_face(rgb_image, box)\n",
    "    embedding = get_embedding(facenet_model, face)\n",
    "    \n",
    "    # So s√°nh v·ªõi references\n",
    "    similarities = [cosine_similarity(embedding, ref_emb) for ref_emb in reference_embeddings]\n",
    "    max_similarity = max(similarities)\n",
    "    \n",
    "    # K·∫øt qu·∫£\n",
    "    if max_similarity > threshold:\n",
    "        result = \"‚úì MATCHED\"\n",
    "        color = (0, 255, 0)\n",
    "    else:\n",
    "        result = \"‚úó UNKNOWN\"\n",
    "        color = (0, 0, 255)\n",
    "    \n",
    "    # V·∫Ω k·∫øt qu·∫£\n",
    "    display_image = image.copy()\n",
    "    x, y, width, height = box\n",
    "    cv2.rectangle(display_image, (x, y), (x+width, y+height), color, 3)\n",
    "    cv2.putText(display_image, f\"{result} ({max_similarity:.3f})\", (x, y-10),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "    \n",
    "    # Hi·ªÉn th·ªã\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cv2.cvtColor(display_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'K·∫øt qu·∫£: {result} | Similarity: {max_similarity:.3f}', fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nK·∫øt qu·∫£: {result}\")\n",
    "    print(f\"Max Similarity: {max_similarity:.4f}\")\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "\n",
    "# Uncomment v√† s·ª≠a ƒë∆∞·ªùng d·∫´n ƒë·ªÉ test\n",
    "test_with_image(r'D:\\UTH-CVIP-assignments\\Solutions\\Gia Luat (face matching)\\gialuat.png', reference_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eead7f",
   "metadata": {},
   "source": [
    "## 10. Th·ªëng k√™ v√† ph√¢n t√≠ch\n",
    "\n",
    "Ph√¢n t√≠ch ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c ·∫£nh tham chi·∫øu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf61cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_reference_embeddings(reference_embeddings):\n",
    "    \"\"\"\n",
    "    Ph√¢n t√≠ch ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c ·∫£nh tham chi·∫øu\n",
    "    \"\"\"\n",
    "    if reference_embeddings is None or len(reference_embeddings) < 2:\n",
    "        print(\"‚ùå C·∫ßn √≠t nh·∫•t 2 reference embeddings ƒë·ªÉ ph√¢n t√≠ch!\")\n",
    "        return\n",
    "    \n",
    "    n = len(reference_embeddings)\n",
    "    similarity_matrix = np.zeros((n, n))\n",
    "    \n",
    "    # T√≠nh similarity matrix\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                similarity_matrix[i][j] = 1.0\n",
    "            else:\n",
    "                sim = cosine_similarity(reference_embeddings[i], reference_embeddings[j])\n",
    "                similarity_matrix[i][j] = sim\n",
    "    \n",
    "    # V·∫Ω heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(similarity_matrix, cmap='RdYlGn', vmin=0, vmax=1)\n",
    "    plt.colorbar(label='Similarity Score')\n",
    "    plt.title('Ma tr·∫≠n ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c ·∫£nh tham chi·∫øu', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Reference Image Index')\n",
    "    plt.ylabel('Reference Image Index')\n",
    "    \n",
    "    # Th√™m gi√° tr·ªã v√†o c√°c √¥\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            text = plt.text(j, i, f'{similarity_matrix[i, j]:.3f}',\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Th·ªëng k√™\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PH√ÇN T√çCH ƒê·ªò T∆Ø∆†NG ƒê·ªíNG GI·ªÆA C√ÅC ·∫¢NH THAM CHI·∫æU\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"S·ªë l∆∞·ª£ng ·∫£nh tham chi·∫øu: {n}\")\n",
    "    \n",
    "    # L·∫•y c√°c gi√° tr·ªã similarity (kh√¥ng t√≠nh ƒë∆∞·ªùng ch√©o)\n",
    "    similarities = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            similarities.append(similarity_matrix[i][j])\n",
    "    \n",
    "    if len(similarities) > 0:\n",
    "        print(f\"\\nƒê·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c c·∫∑p ·∫£nh:\")\n",
    "        print(f\"  - Trung b√¨nh: {np.mean(similarities):.4f}\")\n",
    "        print(f\"  - Cao nh·∫•t:   {np.max(similarities):.4f}\")\n",
    "        print(f\"  - Th·∫•p nh·∫•t:  {np.min(similarities):.4f}\")\n",
    "        print(f\"  - ƒê·ªô l·ªách chu·∫©n: {np.std(similarities):.4f}\")\n",
    "        \n",
    "        if np.min(similarities) < 0.7:\n",
    "            print(f\"\\n‚ö† C·∫¢NH B√ÅO: C√≥ c·∫∑p ·∫£nh tham chi·∫øu c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng < 0.7\")\n",
    "            print(f\"  ƒêi·ªÅu n√†y c√≥ th·ªÉ g√¢y false negative trong nh·∫≠n di·ªán!\")\n",
    "    \n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Ch·∫°y ph√¢n t√≠ch\n",
    "if 'reference_embeddings' in locals() and reference_embeddings is not None:\n",
    "    analyze_reference_embeddings(reference_embeddings)\n",
    "else:\n",
    "    print(\"‚ö† Ch∆∞a c√≥ reference embeddings ƒë·ªÉ ph√¢n t√≠ch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059a721",
   "metadata": {},
   "source": [
    "## üìä T·ªïng k·∫øt\n",
    "\n",
    "### ‚úÖ K·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c:\n",
    "\n",
    "1. **Thu th·∫≠p ·∫£nh tham chi·∫øu**: S·ª≠ d·ª•ng webcam + MTCNN ƒë·ªÉ thu th·∫≠p khu√¥n m·∫∑t\n",
    "2. **Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng**: S·ª≠ d·ª•ng FaceNet ƒë·ªÉ t·∫°o embeddings 512 chi·ªÅu\n",
    "3. **Nh·∫≠n di·ªán th·ªùi gian th·ª±c**: \n",
    "   - Ph√°t hi·ªán khu√¥n m·∫∑t b·∫±ng MTCNN\n",
    "   - Tr√≠ch xu·∫•t embedding b·∫±ng FaceNet\n",
    "   - So s√°nh v·ªõi reference embeddings\n",
    "   - Hi·ªÉn th·ªã k·∫øt qu·∫£ theo ng∆∞·ª°ng 0.7\n",
    "\n",
    "### üìà ƒê·ªô ch√≠nh x√°c:\n",
    "\n",
    "- **Matched** (similarity > 0.7): Hi·ªÉn th·ªã khung xanh ‚úì\n",
    "- **Unknown** (similarity < 0.7): Hi·ªÉn th·ªã khung ƒë·ªè ‚úó\n",
    "\n",
    "### üîß C√°c tham s·ªë c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh:\n",
    "\n",
    "- `threshold`: Ng∆∞·ª°ng similarity (m·∫∑c ƒë·ªãnh 0.7)\n",
    "- `num_samples`: S·ªë ·∫£nh tham chi·∫øu thu th·∫≠p (m·∫∑c ƒë·ªãnh 5)\n",
    "- `level`: C·∫•p ƒë·ªô ph√¢n r√£ wavelet (n·∫øu d√πng wavelet thay FaceNet)\n",
    "\n",
    "### üìÅ File ƒë·∫ßu ra:\n",
    "\n",
    "- `reference_faces/`: Th∆∞ m·ª•c ch·ª©a ·∫£nh tham chi·∫øu\n",
    "- `reference_embeddings.pkl`: File ch·ª©a embeddings ƒë√£ l∆∞u\n",
    "\n",
    "---\n",
    "\n",
    "**L∆∞u √Ω**: Ch∆∞∆°ng tr√¨nh y√™u c·∫ßu webcam ho·∫°t ƒë·ªông v√† √°nh s√°ng ƒë·ªß ƒë·ªÉ MTCNN ph√°t hi·ªán khu√¥n m·∫∑t t·ªët!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
