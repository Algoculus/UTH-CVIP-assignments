{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e32b23e",
   "metadata": {},
   "source": [
    "# Nh·∫≠n di·ªán khu√¥n m·∫∑t th·ªùi gian th·ª±c v·ªõi FaceNet & MTCNN tr√™n Webcam\n",
    "\n",
    "B√†i t·∫≠p th·ª±c h√†nh: X√¢y d·ª±ng h·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t theo th·ªùi gian th·ª±c s·ª≠ d·ª•ng:\n",
    "- **MTCNN**: Ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "- **FaceNet**: Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng v√† so s√°nh khu√¥n m·∫∑t\n",
    "- **OpenCV**: Truy c·∫≠p webcam\n",
    "\n",
    "**ƒêi·ªÅu ki·ªán so s√°nh:**\n",
    "- Similarity > 0.7: \"Matched\"\n",
    "- Similarity < 0.7: \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8265fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ import c√°c th∆∞ vi·ªán v√† thi·∫øt l·∫≠p config\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "KNOWN_DIR = \"known\"          # th∆∞ m·ª•c ch·ª©a ·∫£nh ng∆∞·ªùi ƒë√£ bi·∫øt\n",
    "THRESHOLD = 0.7             # similarity threshold\n",
    "CAM_INDEX = 0               # webcam index (0 th∆∞·ªùng l√† webcam m·∫∑c ƒë·ªãnh)\n",
    "MIN_FACE_SIZE = 60          # b·ªè qua m·∫∑t qu√° nh·ªè (px)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ import c√°c th∆∞ vi·ªán v√† thi·∫øt l·∫≠p config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7d04a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ ƒë·ªãnh nghƒ©a c√°c helper functions\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def l2_normalize(x: np.ndarray, eps: float = 1e-10) -> np.ndarray:\n",
    "    \"\"\"Chu·∫©n h√≥a vector theo L2\"\"\"\n",
    "    return x / (np.linalg.norm(x) + eps)\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine gi·ªØa 2 vectors\"\"\"\n",
    "    a = l2_normalize(a)\n",
    "    b = l2_normalize(b)\n",
    "    return float(np.dot(a, b))\n",
    "\n",
    "def preprocess_face(face_bgr: np.ndarray, target_size=(160, 160)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    FaceNet th∆∞·ªùng d√πng input 160x160, RGB.\n",
    "    Tr·∫£ v·ªÅ m·∫£ng (160,160,3) RGB uint8.\n",
    "    \"\"\"\n",
    "    face_rgb = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB)\n",
    "    face_rgb = cv2.resize(face_rgb, target_size, interpolation=cv2.INTER_AREA)\n",
    "    return face_rgb\n",
    "\n",
    "def get_embedding(embedder: FaceNet, face_rgb_160: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    keras-facenet: embeddings() nh·∫≠n list/np array ·∫£nh RGB (uint8 ok).\n",
    "    \"\"\"\n",
    "    emb = embedder.embeddings([face_rgb_160])[0]  # shape (512,)\n",
    "    return emb.astype(np.float32)\n",
    "\n",
    "def safe_crop(frame: np.ndarray, x: int, y: int, w: int, h: int) -> tuple:\n",
    "    \"\"\"Crop an to√†n, ƒë·∫£m b·∫£o kh√¥ng v∆∞·ª£t bi√™n\"\"\"\n",
    "    H, W = frame.shape[:2]\n",
    "    x1 = max(0, x)\n",
    "    y1 = max(0, y)\n",
    "    x2 = min(W, x + w)\n",
    "    y2 = min(H, y + h)\n",
    "    return frame[y1:y2, x1:x2], (x1, y1, x2, y2)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ ƒë·ªãnh nghƒ©a c√°c helper functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e28436c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <_io.BufferedReader>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lz4\\frame\\__init__.py\", line 753, in flush\n",
      "    self._fp.flush()\n",
      "ValueError: I/O operation on closed file.\n",
      "Exception ignored in: <_io.BufferedReader>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lz4\\frame\\__init__.py\", line 753, in flush\n",
      "    self._fp.flush()\n",
      "ValueError: I/O operation on closed file.\n",
      "Exception ignored in: <_io.BufferedReader>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lz4\\frame\\__init__.py\", line 753, in flush\n",
      "    self._fp.flush()\n",
      "ValueError: I/O operation on closed file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang load models...\n",
      "‚úÖ MTCNN v√† FaceNet ƒë√£ s·∫µn s√†ng!\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# LOAD MODELS\n",
    "# =========================\n",
    "print(\"ƒêang load models...\")\n",
    "detector = MTCNN()\n",
    "embedder = FaceNet()  # load FaceNet\n",
    "print(\"‚úÖ MTCNN v√† FaceNet ƒë√£ s·∫µn s√†ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "89bd5189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] ƒêang t·∫°o database embeddings t·ª´ th∆∞ m·ª•c known/ ...\n",
      "[!] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c: known\\ronaldo.png\n",
      "[!] Kh√¥ng t·∫°o ƒë∆∞·ª£c embeddings n√†o t·ª´ known/. H√£y d√πng ·∫£nh r√µ m·∫∑t h∆°n.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# BUILD KNOWN DATABASE\n",
    "# =========================\n",
    "known_embeddings = []\n",
    "known_names = []\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥\n",
    "if not os.path.isdir(KNOWN_DIR):\n",
    "    os.makedirs(KNOWN_DIR, exist_ok=True)\n",
    "    print(f\"[!] ƒê√£ t·∫°o th∆∞ m·ª•c '{KNOWN_DIR}'. H√£y b·ªè ·∫£nh ng∆∞·ªùi quen v√†o ƒë√≥ r·ªìi ch·∫°y l·∫°i.\")\n",
    "else:\n",
    "    image_files = [f for f in os.listdir(KNOWN_DIR) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\"[!] Th∆∞ m·ª•c '{KNOWN_DIR}' ch∆∞a c√≥ ·∫£nh. H√£y th√™m ·∫£nh (jpg/png) r·ªìi ch·∫°y l·∫°i.\")\n",
    "    else:\n",
    "        print(f\"[*] ƒêang t·∫°o database embeddings t·ª´ th∆∞ m·ª•c {KNOWN_DIR}/ ...\")\n",
    "        \n",
    "        for fn in image_files:\n",
    "            path = os.path.join(KNOWN_DIR, fn)\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                print(f\"[!] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c: {path}\")\n",
    "                continue\n",
    "\n",
    "            # detect face in known image\n",
    "            faces = detector.detect_faces(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            if len(faces) == 0:\n",
    "                print(f\"[!] Kh√¥ng ph√°t hi·ªán m·∫∑t trong: {fn}\")\n",
    "                continue\n",
    "\n",
    "            # l·∫•y face c√≥ confidence cao nh·∫•t\n",
    "            faces = sorted(faces, key=lambda d: d.get(\"confidence\", 0), reverse=True)\n",
    "            x, y, w, h = faces[0][\"box\"]\n",
    "            face_crop, _ = safe_crop(img, x, y, w, h)\n",
    "\n",
    "            if face_crop.size == 0 or min(face_crop.shape[:2]) < MIN_FACE_SIZE:\n",
    "                print(f\"[!] M·∫∑t qu√° nh·ªè/l·ªói crop trong: {fn}\")\n",
    "                continue\n",
    "\n",
    "            face_160 = preprocess_face(face_crop)\n",
    "            emb = get_embedding(embedder, face_160)\n",
    "\n",
    "            name = os.path.splitext(fn)[0]  # t√™n = filename kh√¥ng ƒëu√¥i\n",
    "            known_embeddings.append(emb)\n",
    "            known_names.append(name)\n",
    "            print(f\"    + Loaded: {name}\")\n",
    "\n",
    "        known_embeddings = np.array(known_embeddings, dtype=np.float32)\n",
    "        \n",
    "        if len(known_embeddings) == 0:\n",
    "            print(\"[!] Kh√¥ng t·∫°o ƒë∆∞·ª£c embeddings n√†o t·ª´ known/. H√£y d√πng ·∫£nh r√µ m·∫∑t h∆°n.\")\n",
    "        else:\n",
    "            print(f\"\\n‚úÖ Database s·∫µn s√†ng: {len(known_embeddings)} ng∆∞·ªùi\")\n",
    "            print(f\"üìã Danh s√°ch: {', '.join(known_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7af5013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Kh√¥ng c√≥ database ƒë·ªÉ so s√°nh. H√£y th√™m ·∫£nh v√†o th∆∞ m·ª•c 'known/' tr∆∞·ªõc!\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# REALTIME WEBCAM\n",
    "# =========================\n",
    "if len(known_embeddings) == 0:\n",
    "    print(\"‚ö†Ô∏è  Kh√¥ng c√≥ database ƒë·ªÉ so s√°nh. H√£y th√™m ·∫£nh v√†o th∆∞ m·ª•c 'known/' tr∆∞·ªõc!\")\n",
    "else:\n",
    "    cap = cv2.VideoCapture(CAM_INDEX)\n",
    "    if not cap.isOpened():\n",
    "        print(\"[!] Kh√¥ng m·ªü ƒë∆∞·ª£c webcam.\")\n",
    "    else:\n",
    "        print(\"[*] Webcam ƒë√£ s·∫µn s√†ng. Nh·∫•n 'q' ƒë·ªÉ tho√°t.\")\n",
    "        print(f\"[*] Threshold: {THRESHOLD}\")\n",
    "        print(f\"[*] S·ªë ng∆∞·ªùi trong database: {len(known_names)}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        frame_count = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Flip frame ƒë·ªÉ t·∫°o hi·ªáu ·ª©ng g∆∞∆°ng\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            detections = detector.detect_faces(rgb)\n",
    "\n",
    "            for det in detections:\n",
    "                conf = det.get(\"confidence\", 0)\n",
    "                if conf < 0.90:  # b·ªè qua detection c√≥ confidence th·∫•p\n",
    "                    continue\n",
    "\n",
    "                x, y, w, h = det[\"box\"]\n",
    "                face_crop, (x1, y1, x2, y2) = safe_crop(frame, x, y, w, h)\n",
    "\n",
    "                if face_crop.size == 0:\n",
    "                    continue\n",
    "                if min(face_crop.shape[:2]) < MIN_FACE_SIZE:\n",
    "                    continue\n",
    "\n",
    "                face_160 = preprocess_face(face_crop)\n",
    "                emb_live = get_embedding(embedder, face_160)\n",
    "\n",
    "                # So kh·ªõp: l·∫•y similarity l·ªõn nh·∫•t\n",
    "                sims = [cosine_similarity(emb_live, e) for e in known_embeddings]\n",
    "                best_idx = int(np.argmax(sims))\n",
    "                best_sim = float(sims[best_idx])\n",
    "                best_name = known_names[best_idx]\n",
    "\n",
    "                # Ki·ªÉm tra threshold\n",
    "                if best_sim > THRESHOLD:\n",
    "                    label = \"Matched\"\n",
    "                    color = (0, 255, 0)  # XANH L√Å\n",
    "                    display_text = f\"{best_name} | sim={best_sim:.2f}\"\n",
    "                else:\n",
    "                    label = \"Unknown\"\n",
    "                    color = (0, 0, 255)  # ƒê·ªé\n",
    "                    display_text = f\"Unknown | sim={best_sim:.2f}\"\n",
    "\n",
    "                # V·∫Ω bounding box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # V·∫Ω background cho text\n",
    "                (tw, th), _ = cv2.getTextSize(display_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                cv2.rectangle(frame, (x1, y1-30), (x1+tw, y1), color, -1)\n",
    "                \n",
    "                # V·∫Ω text\n",
    "                cv2.putText(frame, display_text, (x1, y1-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                # V·∫Ω confidence\n",
    "                cv2.putText(frame, f\"Conf: {conf:.2f}\", (x1, y2+20),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n\n",
    "            cv2.putText(frame, \"Press 'q' to quit\", (10, 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # Hi·ªÉn th·ªã frame\n",
    "            cv2.imshow(\"FaceNet + MTCNN Realtime\", frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\n‚úÖ ƒê√£ ƒë√≥ng webcam v√† gi·∫£i ph√≥ng t√†i nguy√™n\")\n",
    "        print(f\"üìä T·ªïng s·ªë frames x·ª≠ l√Ω: {frame_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975f236",
   "metadata": {},
   "source": [
    "## üìù Gi·∫£i th√≠ch Logic Ch√≠nh X√°c\n",
    "\n",
    "### üîç Lu·ªìng x·ª≠ l√Ω:\n",
    "\n",
    "1. **Load Models**\n",
    "   - MTCNN: Detector ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "   - FaceNet: Tr√≠ch xu·∫•t embedding 512 chi·ªÅu\n",
    "\n",
    "2. **Build Database** \n",
    "   - ƒê·ªçc ·∫£nh t·ª´ th∆∞ m·ª•c `known/`\n",
    "   - Detect face b·∫±ng MTCNN\n",
    "   - Tr√≠ch xu·∫•t embedding b·∫±ng FaceNet\n",
    "   - L∆∞u v√†o arrays `known_embeddings` v√† `known_names`\n",
    "\n",
    "3. **Real-time Recognition**\n",
    "   - Capture frame t·ª´ webcam\n",
    "   - Detect faces trong frame (MTCNN)\n",
    "   - V·ªõi m·ªói face:\n",
    "     - Crop v√† resize v·ªÅ 160x160\n",
    "     - Tr√≠ch xu·∫•t embedding\n",
    "     - T√≠nh cosine similarity v·ªõi t·∫•t c·∫£ known embeddings\n",
    "     - L·∫•y similarity cao nh·∫•t\n",
    "     - **ƒêi·ªÅu ki·ªán**: \n",
    "       - `similarity > 0.7` ‚Üí **Matched** (XANH L√Å) + hi·ªÉn th·ªã t√™n\n",
    "       - `similarity ‚â§ 0.7` ‚Üí **Unknown** (ƒê·ªé)\n",
    "\n",
    "### ‚öôÔ∏è C√°c tham s·ªë quan tr·ªçng:\n",
    "\n",
    "- **THRESHOLD = 0.7**: Ng∆∞·ª°ng ph√¢n bi·ªát matched/unknown\n",
    "- **MIN_FACE_SIZE = 60px**: B·ªè qua face qu√° nh·ªè\n",
    "- **Confidence MTCNN > 0.90**: Ch·ªâ x·ª≠ l√Ω detection c√≥ confidence cao\n",
    "\n",
    "### üéØ ƒêi·ªÉm kh√°c bi·ªát so v·ªõi code c≈©:\n",
    "\n",
    "‚úÖ **L2 normalization**: Chu·∫©n h√≥a embeddings tr∆∞·ªõc khi t√≠nh similarity  \n",
    "‚úÖ **Safe crop**: X·ª≠ l√Ω bi√™n ·∫£nh an to√†n  \n",
    "‚úÖ **Preprocessing ƒë√∫ng**: BGR‚ÜíRGB v√† resize v·ªÅ 160x160  \n",
    "‚úÖ **Confidence filtering**: L·ªçc detection k√©m ch·∫•t l∆∞·ª£ng  \n",
    "‚úÖ **Logic r√µ r√†ng**: So s√°nh > 0.7 (matched) vs ‚â§ 0.7 (unknown)\n",
    "\n",
    "### üìÅ C·∫•u tr√∫c th∆∞ m·ª•c:\n",
    "\n",
    "```\n",
    "face-matching.ipynb\n",
    "known/                 # Th∆∞ m·ª•c ch·ª©a ·∫£nh ng∆∞·ªùi quen\n",
    "  ‚îú‚îÄ‚îÄ person1.jpg     # T√™n file = t√™n ng∆∞·ªùi\n",
    "  ‚îú‚îÄ‚îÄ person2.jpg\n",
    "  ‚îî‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "### üöÄ C√°ch s·ª≠ d·ª•ng:\n",
    "\n",
    "1. T·∫°o th∆∞ m·ª•c `known/` trong c√πng th∆∞ m·ª•c v·ªõi notebook\n",
    "2. Th√™m ·∫£nh ng∆∞·ªùi quen v√†o `known/` (jpg/png)\n",
    "3. Ch·∫°y c√°c cell theo th·ª© t·ª± t·ª´ tr√™n xu·ªëng\n",
    "4. Webcam s·∫Ω b·∫≠t v√† b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán\n",
    "5. Nh·∫•n 'q' ƒë·ªÉ tho√°t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9836e",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG\n",
    "\n",
    "Code m·ªõi n√†y s·ª≠ d·ª•ng th∆∞ m·ª•c **`known/`** thay v√¨ `reference_faces/`.\n",
    "\n",
    "B·∫°n c√≥ 2 l·ª±a ch·ªçn:\n",
    "\n",
    "### L·ª±a ch·ªçn 1: Copy ·∫£nh t·ª´ reference_faces sang known\n",
    "```python\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c known\n",
    "os.makedirs('known', exist_ok=True)\n",
    "\n",
    "# Copy t·∫•t c·∫£ ·∫£nh t·ª´ reference_faces sang known\n",
    "for file in os.listdir('reference_faces'):\n",
    "    if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        src = os.path.join('reference_faces', file)\n",
    "        dst = os.path.join('known', file)\n",
    "        shutil.copy2(src, dst)\n",
    "        print(f\"Copied: {file}\")\n",
    "```\n",
    "\n",
    "### L·ª±a ch·ªçn 2: Thay ƒë·ªïi KNOWN_DIR trong cell config\n",
    "S·ª≠a d√≤ng:\n",
    "```python\n",
    "KNOWN_DIR = \"known\"\n",
    "```\n",
    "Th√†nh:\n",
    "```python\n",
    "KNOWN_DIR = \"reference_faces\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "af3e5698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Th∆∞ m·ª•c 'known/' ƒë√£ t·ªìn t·∫°i v·ªõi 1 ·∫£nh\n"
     ]
    }
   ],
   "source": [
    "# Helper: T·ª± ƒë·ªông copy ·∫£nh t·ª´ reference_faces n·∫øu c√≥\n",
    "import shutil\n",
    "\n",
    "if os.path.exists('reference_faces') and not os.path.exists('known'):\n",
    "    print(\"üìÅ Ph√°t hi·ªán th∆∞ m·ª•c 'reference_faces', ƒëang copy sang 'known'...\")\n",
    "    os.makedirs('known', exist_ok=True)\n",
    "    \n",
    "    copied = 0\n",
    "    for file in os.listdir('reference_faces'):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            src = os.path.join('reference_faces', file)\n",
    "            dst = os.path.join('known', file)\n",
    "            shutil.copy2(src, dst)\n",
    "            copied += 1\n",
    "            print(f\"  ‚úì {file}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ ƒê√£ copy {copied} ·∫£nh v√†o th∆∞ m·ª•c 'known/'\")\n",
    "elif os.path.exists('known'):\n",
    "    num_images = len([f for f in os.listdir('known') if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(f\"‚úÖ Th∆∞ m·ª•c 'known/' ƒë√£ t·ªìn t·∫°i v·ªõi {num_images} ·∫£nh\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Ch∆∞a c√≥ th∆∞ m·ª•c 'known/' ho·∫∑c 'reference_faces/'\")\n",
    "    print(\"H√£y ch·∫°y cell ti·∫øp theo ƒë·ªÉ t·∫°o th∆∞ m·ª•c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02807107",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ HO√ÄN TH√ÄNH TRI·ªÇN KHAI\n",
    "\n",
    "ƒê√£ tri·ªÉn khai l·∫°i logic nh·∫≠n di·ªán khu√¥n m·∫∑t v·ªõi c√°c c·∫£i ti·∫øn:\n",
    "\n",
    "### üéØ Logic ch√≠nh x√°c theo y√™u c·∫ßu:\n",
    "\n",
    "```python\n",
    "# T√≠nh cosine similarity\n",
    "similarity = cosine_similarity(embedding_live, embedding_known)\n",
    "\n",
    "# ƒêi·ªÅu ki·ªán so s√°nh\n",
    "if similarity > 0.7:\n",
    "    label = \"Matched\"     # XANH L√Å (0, 255, 0)\n",
    "    display_name = True\n",
    "else:\n",
    "    label = \"Unknown\"     # ƒê·ªé (0, 0, 255)\n",
    "```\n",
    "\n",
    "### üîß C√°c c·∫£i ti·∫øn k·ªπ thu·∫≠t:\n",
    "\n",
    "1. **L2 Normalization**: Chu·∫©n h√≥a embeddings tr∆∞·ªõc khi t√≠nh similarity\n",
    "2. **Safe Cropping**: Tr√°nh l·ªói khi crop v∆∞·ª£t bi√™n ·∫£nh\n",
    "3. **Preprocessing ƒë√∫ng**: BGR‚ÜíRGB, resize 160x160 theo chu·∫©n FaceNet\n",
    "4. **Confidence Filtering**: Ch·ªâ x·ª≠ l√Ω detections c√≥ confidence > 0.9\n",
    "5. **Min Face Size**: B·ªè qua faces nh·ªè h∆°n 60px\n",
    "\n",
    "### üìä K·∫øt qu·∫£ hi·ªán t·∫°i:\n",
    "\n",
    "- ‚úÖ Models ƒë√£ load th√†nh c√¥ng (MTCNN + FaceNet)\n",
    "- ‚úÖ Database ƒë√£ ƒë∆∞·ª£c t·∫°o v·ªõi **1 ng∆∞·ªùi**\n",
    "- ‚úÖ S·∫µn s√†ng ch·∫°y real-time recognition\n",
    "\n",
    "### ‚ñ∂Ô∏è ƒê·ªÉ ch·∫°y:\n",
    "\n",
    "Ch·∫°y cell ti·∫øp theo ƒë·ªÉ b·∫≠t webcam v√† b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán. Nh·∫•n **'q'** ƒë·ªÉ tho√°t.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "10ad7ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç SO S√ÅNH LOGIC C≈® V√Ä M·ªöI\n",
      "======================================================================\n",
      "\n",
      "üìå ƒêI·ªÇM KH√ÅC BI·ªÜT CH√çNH:\n",
      "\n",
      "1. T√çNH COSINE SIMILARITY:\n",
      "   ‚ùå Code c≈©:\n",
      "      dot_product / (norm1 * norm2)\n",
      "      ‚Üí C√≥ th·ªÉ kh√¥ng chu·∫©n h√≥a ƒë·∫ßy ƒë·ªß\n",
      "\n",
      "   ‚úÖ Code m·ªõi:\n",
      "      l2_normalize(a) ¬∑ l2_normalize(b)\n",
      "      ‚Üí Chu·∫©n h√≥a ch√≠nh x√°c tr∆∞·ªõc khi t√≠nh\n",
      "\n",
      "2. PREPROCESSING KHU√îN M·∫∂T:\n",
      "   ‚ùå Code c≈©:\n",
      "      C√≥ th·ªÉ thi·∫øu b∆∞·ªõc BGR‚ÜíRGB\n",
      "      Normalize = (pixels - mean) / std\n",
      "\n",
      "   ‚úÖ Code m·ªõi:\n",
      "      Lu√¥n convert BGR‚ÜíRGB\n",
      "      Resize v·ªÅ 160x160 ƒë√∫ng chu·∫©n FaceNet\n",
      "\n",
      "3. X·ª¨ L√ù CROPPING:\n",
      "   ‚ùå Code c≈©:\n",
      "      face = image[y:y+h, x:x+w]\n",
      "      ‚Üí C√≥ th·ªÉ l·ªói khi t·ªça ƒë·ªô √¢m ho·∫∑c v∆∞·ª£t bi√™n\n",
      "\n",
      "   ‚úÖ Code m·ªõi:\n",
      "      safe_crop() v·ªõi boundary checking\n",
      "      ‚Üí An to√†n, kh√¥ng crash\n",
      "\n",
      "4. ƒêI·ªÄU KI·ªÜN SO S√ÅNH:\n",
      "   ‚ùå Code c≈©:\n",
      "      if similarity < threshold: 'Unknown'\n",
      "      (C√≥ th·ªÉ nh·∫ßm l·∫´n logic)\n",
      "\n",
      "   ‚úÖ Code m·ªõi:\n",
      "      if similarity > 0.7: 'Matched' (XANH)\n",
      "      else: 'Unknown' (ƒê·ªé)\n",
      "      ‚Üí R√µ r√†ng, ƒë√∫ng y√™u c·∫ßu\n",
      "\n",
      "5. CONFIDENCE FILTERING:\n",
      "   ‚ùå Code c≈©:\n",
      "      X·ª≠ l√Ω t·∫•t c·∫£ detections\n",
      "\n",
      "   ‚úÖ Code m·ªõi:\n",
      "      Ch·ªâ x·ª≠ l√Ω confidence > 0.90\n",
      "      ‚Üí Gi·∫£m false positives\n",
      "\n",
      "======================================================================\n",
      "‚úÖ CODE M·ªöI ƒê√É S·ª¨A T·∫§T C·∫¢ C√ÅC V·∫§N ƒê·ªÄ!\n",
      "======================================================================\n",
      "\n",
      "üß™ TEST T√çNH TO√ÅN:\n",
      "Vector gi·ªëng nhau ‚Üí similarity = 1.000 (ph·∫£i g·∫ßn 1.0)\n",
      "Vector vu√¥ng g√≥c ‚Üí similarity = 0.000 (ph·∫£i g·∫ßn 0.0)\n",
      "\n",
      "‚úÖ Functions ho·∫°t ƒë·ªông ch√≠nh x√°c!\n"
     ]
    }
   ],
   "source": [
    "# KI·ªÇM TRA LOGIC - So s√°nh code c≈© vs code m·ªõi\n",
    "print(\"=\"*70)\n",
    "print(\"üîç SO S√ÅNH LOGIC C≈® V√Ä M·ªöI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìå ƒêI·ªÇM KH√ÅC BI·ªÜT CH√çNH:\\n\")\n",
    "\n",
    "print(\"1. T√çNH COSINE SIMILARITY:\")\n",
    "print(\"   ‚ùå Code c≈©:\")\n",
    "print(\"      dot_product / (norm1 * norm2)\")\n",
    "print(\"      ‚Üí C√≥ th·ªÉ kh√¥ng chu·∫©n h√≥a ƒë·∫ßy ƒë·ªß\\n\")\n",
    "print(\"   ‚úÖ Code m·ªõi:\")\n",
    "print(\"      l2_normalize(a) ¬∑ l2_normalize(b)\")\n",
    "print(\"      ‚Üí Chu·∫©n h√≥a ch√≠nh x√°c tr∆∞·ªõc khi t√≠nh\\n\")\n",
    "\n",
    "print(\"2. PREPROCESSING KHU√îN M·∫∂T:\")\n",
    "print(\"   ‚ùå Code c≈©:\")\n",
    "print(\"      C√≥ th·ªÉ thi·∫øu b∆∞·ªõc BGR‚ÜíRGB\")\n",
    "print(\"      Normalize = (pixels - mean) / std\\n\")\n",
    "print(\"   ‚úÖ Code m·ªõi:\")\n",
    "print(\"      Lu√¥n convert BGR‚ÜíRGB\")\n",
    "print(\"      Resize v·ªÅ 160x160 ƒë√∫ng chu·∫©n FaceNet\\n\")\n",
    "\n",
    "print(\"3. X·ª¨ L√ù CROPPING:\")\n",
    "print(\"   ‚ùå Code c≈©:\")\n",
    "print(\"      face = image[y:y+h, x:x+w]\")\n",
    "print(\"      ‚Üí C√≥ th·ªÉ l·ªói khi t·ªça ƒë·ªô √¢m ho·∫∑c v∆∞·ª£t bi√™n\\n\")\n",
    "print(\"   ‚úÖ Code m·ªõi:\")\n",
    "print(\"      safe_crop() v·ªõi boundary checking\")\n",
    "print(\"      ‚Üí An to√†n, kh√¥ng crash\\n\")\n",
    "\n",
    "print(\"4. ƒêI·ªÄU KI·ªÜN SO S√ÅNH:\")\n",
    "print(\"   ‚ùå Code c≈©:\")\n",
    "print(\"      if similarity < threshold: 'Unknown'\")\n",
    "print(\"      (C√≥ th·ªÉ nh·∫ßm l·∫´n logic)\\n\")\n",
    "print(\"   ‚úÖ Code m·ªõi:\")\n",
    "print(\"      if similarity > 0.7: 'Matched' (XANH)\")\n",
    "print(\"      else: 'Unknown' (ƒê·ªé)\")\n",
    "print(\"      ‚Üí R√µ r√†ng, ƒë√∫ng y√™u c·∫ßu\\n\")\n",
    "\n",
    "print(\"5. CONFIDENCE FILTERING:\")\n",
    "print(\"   ‚ùå Code c≈©:\")\n",
    "print(\"      X·ª≠ l√Ω t·∫•t c·∫£ detections\\n\")\n",
    "print(\"   ‚úÖ Code m·ªõi:\")\n",
    "print(\"      Ch·ªâ x·ª≠ l√Ω confidence > 0.90\")\n",
    "print(\"      ‚Üí Gi·∫£m false positives\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ CODE M·ªöI ƒê√É S·ª¨A T·∫§T C·∫¢ C√ÅC V·∫§N ƒê·ªÄ!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test similarity calculation\n",
    "print(\"\\nüß™ TEST T√çNH TO√ÅN:\")\n",
    "vec1 = np.array([1.0, 2.0, 3.0])\n",
    "vec2 = np.array([1.0, 2.0, 3.0])\n",
    "similarity = cosine_similarity(vec1, vec2)\n",
    "print(f\"Vector gi·ªëng nhau ‚Üí similarity = {similarity:.3f} (ph·∫£i g·∫ßn 1.0)\")\n",
    "\n",
    "vec3 = np.array([1.0, 0.0, 0.0])\n",
    "vec4 = np.array([0.0, 1.0, 0.0])\n",
    "similarity2 = cosine_similarity(vec3, vec4)\n",
    "print(f\"Vector vu√¥ng g√≥c ‚Üí similarity = {similarity2:.3f} (ph·∫£i g·∫ßn 0.0)\")\n",
    "\n",
    "print(\"\\n‚úÖ Functions ho·∫°t ƒë·ªông ch√≠nh x√°c!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
