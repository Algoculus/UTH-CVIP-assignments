{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e2725e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìã KI·ªÇM TRA Y√äU C·∫¶U B√ÄI T·∫¨P\n",
    "\n",
    "## Y√™u c·∫ßu ƒë·ªÅ b√†i:\n",
    "‚úÖ **Nh·∫≠n di·ªán khu√¥n m·∫∑t th·ªùi gian th·ª±c v·ªõi FaceNet & MTCNN tr√™n Webcam**\n",
    "\n",
    "## C√°c b∆∞·ªõc ch√≠nh theo y√™u c·∫ßu:\n",
    "\n",
    "### 1. Thao t√°c truy c·∫≠p v√† thu th·∫≠p th√¥ng tin qua webcam b·∫±ng th∆∞ vi·ªán OpenCV\n",
    "- ‚úÖ **ƒê√£ th·ª±c hi·ªán**: Cell 13 (h√†m `real_time_face_recognition`) v√† Cell 17 (h√†m `advanced_face_recognition_with_logging`)\n",
    "- ‚úÖ S·ª≠ d·ª•ng `cv2.VideoCapture(0)` ƒë·ªÉ truy c·∫≠p webcam\n",
    "- ‚úÖ Thu th·∫≠p th√¥ng tin: FPS, s·ªë khu√¥n m·∫∑t, th·ªùi gian x·ª≠ l√Ω, l·ªãch s·ª≠ nh·∫≠n di·ªán\n",
    "- ‚úÖ L∆∞u log v√†o file ƒë·ªÉ ph√¢n t√≠ch\n",
    "\n",
    "### 2. T√≠ch h·ª£p MTCNN ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "- ‚úÖ **ƒê√£ th·ª±c hi·ªán**: Cell 6 (kh·ªüi t·∫°o MTCNN)\n",
    "- ‚úÖ `detector = MTCNN()` - kh·ªüi t·∫°o detector\n",
    "- ‚úÖ `detector.detect_faces(rgb_frame)` - ph√°t hi·ªán khu√¥n m·∫∑t trong frame\n",
    "- ‚úÖ Tr·∫£ v·ªÅ bounding box `[x, y, width, height]` v√† confidence\n",
    "- ‚úÖ H·ªó tr·ª£ ph√°t hi·ªán nhi·ªÅu khu√¥n m·∫∑t c√πng l√∫c\n",
    "\n",
    "### 3. S·ª≠ d·ª•ng FaceNet ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng v√† so s√°nh khu√¥n m·∫∑t theo th·ªùi gian th·ª±c\n",
    "- ‚úÖ **ƒê√£ th·ª±c hi·ªán**: Cell 6 (kh·ªüi t·∫°o FaceNet), Cell 8 (functions), Cell 11 (comparison)\n",
    "- ‚úÖ `facenet_model = FaceNet()` - kh·ªüi t·∫°o model\n",
    "- ‚úÖ `get_embedding()` - tr√≠ch xu·∫•t embedding vector (512 chi·ªÅu)\n",
    "- ‚úÖ `cosine_similarity()` - t√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa 2 embeddings\n",
    "- ‚úÖ `recognize_face()` - so s√°nh v·ªõi database reference faces\n",
    "\n",
    "### 4. ƒêi·ªÅu ki·ªán so s√°nh theo y√™u c·∫ßu\n",
    "- ‚úÖ **Similarity > 0.7**: Hi·ªÉn th·ªã t√™n ng∆∞·ªùi (Matched) - **M√†u XANH L√Å**\n",
    "- ‚úÖ **Similarity < 0.7**: Hi·ªÉn th·ªã \"Unknown\" - **M√†u ƒê·ªé**\n",
    "- ‚úÖ Threshold m·∫∑c ƒë·ªãnh = 0.7 (c√≥ th·ªÉ t√πy ch·ªânh)\n",
    "\n",
    "## T√≠nh nƒÉng b·ªï sung (n√¢ng cao):\n",
    "- üìä Dashboard ƒë√°nh gi√° real-time (FPS, detection rate, statistics)\n",
    "- üìù Logging system ƒë·ªÉ thu th·∫≠p v√† ph√¢n t√≠ch d·ªØ li·ªáu\n",
    "- üé® Visualization c·∫£i ti·∫øn v·ªõi corner markers v√† th√¥ng tin chi ti·∫øt\n",
    "- ‚å®Ô∏è Interactive controls (Space, S, D, L, Q)\n",
    "- üìà Ph√¢n t√≠ch log sau khi k·∫øt th√∫c\n",
    "\n",
    "## C·∫•u tr√∫c code theo chu·∫©n:\n",
    "1. ‚úÖ Import th∆∞ vi·ªán ƒë·∫ßy ƒë·ªß\n",
    "2. ‚úÖ Kh·ªüi t·∫°o MTCNN v√† FaceNet\n",
    "3. ‚úÖ ƒê·ªãnh nghƒ©a h√†m x·ª≠ l√Ω khu√¥n m·∫∑t\n",
    "4. ‚úÖ Load v√† x·ª≠ l√Ω ·∫£nh tham chi·∫øu\n",
    "5. ‚úÖ H√†m so s√°nh v·ªõi cosine similarity\n",
    "6. ‚úÖ Ch∆∞∆°ng tr√¨nh ch√≠nh nh·∫≠n di·ªán real-time\n",
    "7. ‚úÖ Logging v√† thu th·∫≠p th√¥ng tin\n",
    "8. ‚úÖ Ph√¢n t√≠ch v√† ƒë√°nh gi√° k·∫øt qu·∫£\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6512fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICATION CODE - Ki·ªÉm tra logic nh·∫≠n di·ªán\n",
    "print(\"=\"*70)\n",
    "print(\"üîç KI·ªÇM TRA LOGIC NH·∫¨N DI·ªÜN KHU√îN M·∫∂T\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test 1: Ki·ªÉm tra threshold logic\n",
    "print(\"\\n1Ô∏è‚É£  TEST ƒêI·ªÄU KI·ªÜN SO S√ÅNH (Threshold = 0.7):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "test_similarities = [0.95, 0.85, 0.75, 0.70, 0.69, 0.65, 0.50, 0.30]\n",
    "print(f\"{'Similarity':<15} {'ƒêi·ªÅu ki·ªán':<15} {'K·∫øt qu·∫£ hi·ªÉn th·ªã':<25} {'M√†u'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for sim in test_similarities:\n",
    "    if sim > 0.7:\n",
    "        condition = \"> 0.7\"\n",
    "        result = \"Matched (T√™n ng∆∞·ªùi)\"\n",
    "        color = \"XANH L√Å (0,255,0)\"\n",
    "        icon = \"‚úÖ\"\n",
    "    else:\n",
    "        condition = \"< 0.7\"  \n",
    "        result = \"Unknown\"\n",
    "        color = \"ƒê·ªé (0,0,255)\"\n",
    "        icon = \"‚ùå\"\n",
    "    \n",
    "    print(f\"{icon} {sim:<13.2f} {condition:<15} {result:<25} {color}\")\n",
    "\n",
    "# Test 2: Ki·ªÉm tra c√°c components c√≥ s·∫µn\n",
    "print(\"\\n2Ô∏è‚É£  KI·ªÇM TRA C√ÅC COMPONENTS:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "components_status = {\n",
    "    \"MTCNN Detector\": 'detector' in dir(),\n",
    "    \"FaceNet Model\": 'facenet_model' in dir(),\n",
    "    \"Reference Embeddings\": 'reference_embeddings' in dir() and len(reference_embeddings) > 0,\n",
    "    \"Extract Face Function\": 'extract_face' in dir(),\n",
    "    \"Get Embedding Function\": 'get_embedding' in dir(),\n",
    "    \"Cosine Similarity Function\": 'cosine_similarity' in dir(),\n",
    "    \"Recognize Face Function\": 'recognize_face' in dir(),\n",
    "    \"Real-time Recognition Function\": 'real_time_face_recognition' in dir(),\n",
    "    \"Advanced Logging Function\": 'advanced_face_recognition_with_logging' in dir()\n",
    "}\n",
    "\n",
    "for component, status in components_status.items():\n",
    "    icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "    status_text = \"S·∫¥N S√ÄNG\" if status else \"CH∆ØA S·∫¥N S√ÄNG\"\n",
    "    print(f\"{icon} {component:<35} : {status_text}\")\n",
    "\n",
    "# Test 3: Ki·ªÉm tra reference faces\n",
    "print(\"\\n3Ô∏è‚É£  KI·ªÇM TRA REFERENCE FACES:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "if 'reference_embeddings' in dir():\n",
    "    if len(reference_embeddings) > 0:\n",
    "        print(f\"‚úÖ S·ªë l∆∞·ª£ng khu√¥n m·∫∑t tham chi·∫øu: {len(reference_embeddings)}\")\n",
    "        print(f\"üìã Danh s√°ch: {', '.join(reference_embeddings.keys())}\")\n",
    "        print(f\"üìä K√≠ch th∆∞·ªõc embedding: {len(next(iter(reference_embeddings.values())))} chi·ªÅu\")\n",
    "    else:\n",
    "        print(\"‚ùå Ch∆∞a c√≥ khu√¥n m·∫∑t tham chi·∫øu n√†o!\")\n",
    "        print(\"‚ö†Ô∏è  Vui l√≤ng th√™m ·∫£nh v√†o th∆∞ m·ª•c 'reference_faces/' v√† ch·∫°y l·∫°i Cell 9\")\n",
    "else:\n",
    "    print(\"‚ùå Bi·∫øn reference_embeddings ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o\")\n",
    "\n",
    "# Test 4: Ki·ªÉm tra lu·ªìng x·ª≠ l√Ω\n",
    "print(\"\\n4Ô∏è‚É£  LU·ªíNG X·ª¨ L√ù NH·∫¨N DI·ªÜN:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"üé• Webcam (OpenCV)\")\n",
    "print(\"  ‚Üì cv2.VideoCapture(0)\")\n",
    "print(\"üì∏ Capture Frame\")\n",
    "print(\"  ‚Üì cv2.cvtColor(BGR ‚Üí RGB)\")\n",
    "print(\"üîç MTCNN Detection\")\n",
    "print(\"  ‚Üì detector.detect_faces()\")\n",
    "print(\"üì¶ Extract Face & Resize (160x160)\")\n",
    "print(\"  ‚Üì Image.resize()\")\n",
    "print(\"üß† FaceNet Embedding\")\n",
    "print(\"  ‚Üì facenet_model.embeddings()\")\n",
    "print(\"üìê Cosine Similarity\")\n",
    "print(\"  ‚Üì np.dot() / (norm1 * norm2)\")\n",
    "print(\"‚öñÔ∏è  Compare with Threshold (0.7)\")\n",
    "print(\"  ‚îú‚îÄ > 0.7 ‚Üí ‚úÖ Matched (XANH L√Å)\")\n",
    "print(\"  ‚îî‚îÄ < 0.7 ‚Üí ‚ùå Unknown (ƒê·ªé)\")\n",
    "print(\"üñºÔ∏è  Display Result\")\n",
    "\n",
    "# Test 5: T·ªïng k·∫øt\n",
    "print(\"\\n5Ô∏è‚É£  T·ªîNG K·∫æT KI·ªÇM TRA:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "all_ready = all(components_status.values())\n",
    "has_references = 'reference_embeddings' in dir() and len(reference_embeddings) > 0\n",
    "\n",
    "if all_ready and has_references:\n",
    "    print(\"‚úÖ ‚úÖ ‚úÖ H·ªÜ TH·ªêNG S·∫¥N S√ÄNG HO·∫†T ƒê·ªòNG!\")\n",
    "    print(\"\\nüìå ƒê·ªÉ ch·∫°y nh·∫≠n di·ªán:\")\n",
    "    print(\"   ‚Ä¢ Ch∆∞∆°ng tr√¨nh c∆° b·∫£n: Cell 13\")\n",
    "    print(\"   ‚Ä¢ Ch∆∞∆°ng tr√¨nh n√¢ng cao (c√≥ logging): Cell 17\")\n",
    "elif all_ready and not has_references:\n",
    "    print(\"‚ö†Ô∏è  H·ªÜ TH·ªêNG THI·∫æU REFERENCE FACES\")\n",
    "    print(\"üëâ Th√™m ·∫£nh khu√¥n m·∫∑t v√†o th∆∞ m·ª•c 'reference_faces/' v√† ch·∫°y Cell 9\")\n",
    "else:\n",
    "    print(\"‚ùå H·ªÜ TH·ªêNG CH∆ØA S·∫¥N S√ÄNG\")\n",
    "    print(\"üëâ Ch·∫°y l·∫°i c√°c cell t·ª´ ƒë·∫ßu theo th·ª© t·ª±\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ HO√ÄN TH√ÄNH KI·ªÇM TRA!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e32b23e",
   "metadata": {},
   "source": [
    "# Nh·∫≠n di·ªán khu√¥n m·∫∑t th·ªùi gian th·ª±c v·ªõi FaceNet & MTCNN tr√™n Webcam\n",
    "\n",
    "B√†i t·∫≠p th·ª±c h√†nh: X√¢y d·ª±ng h·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t theo th·ªùi gian th·ª±c s·ª≠ d·ª•ng:\n",
    "- **MTCNN**: Ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "- **FaceNet**: Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng v√† so s√°nh khu√¥n m·∫∑t\n",
    "- **OpenCV**: Truy c·∫≠p webcam\n",
    "\n",
    "**ƒêi·ªÅu ki·ªán so s√°nh:**\n",
    "- Similarity > 0.7: \"Matched\"\n",
    "- Similarity < 0.7: \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a2c917",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 1: C√†i ƒë·∫∑t v√† Import th∆∞ vi·ªán c·∫ßn thi·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0da730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "# !pip install opencv-python mtcnn keras-facenet tensorflow numpy pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad65fbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th∆∞ vi·ªán ƒë√£ ƒë∆∞·ª£c import th√†nh c√¥ng!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "import os\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Th∆∞ vi·ªán ƒë√£ ƒë∆∞·ª£c import th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbced1d",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 2: Kh·ªüi t·∫°o MTCNN v√† FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb0fc31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <_io.BufferedReader>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lz4\\frame\\__init__.py\", line 753, in flush\n",
      "    self._fp.flush()\n",
      "ValueError: I/O operation on closed file.\n",
      "Exception ignored in: <_io.BufferedReader>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lz4\\frame\\__init__.py\", line 753, in flush\n",
      "    self._fp.flush()\n",
      "ValueError: I/O operation on closed file.\n",
      "Exception ignored in: <_io.BufferedReader>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lz4\\frame\\__init__.py\", line 753, in flush\n",
      "    self._fp.flush()\n",
      "ValueError: I/O operation on closed file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTCNN detector ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o!\n",
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "FaceNet model ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o!\n",
      "FaceNet embedding size: 512\n"
     ]
    }
   ],
   "source": [
    "# Kh·ªüi t·∫°o MTCNN detector ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "detector = MTCNN()\n",
    "print(\"MTCNN detector ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o!\")\n",
    "\n",
    "# Kh·ªüi t·∫°o FaceNet model ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng\n",
    "facenet_model = FaceNet()\n",
    "print(\"FaceNet model ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o!\")\n",
    "print(f\"FaceNet embedding size: {facenet_model.model.output_shape[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08001ee",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 3: Chu·∫©n b·ªã ·∫£nh tham chi·∫øu (Reference Faces)\n",
    "\n",
    "Chu·∫©n b·ªã ·∫£nh khu√¥n m·∫∑t tham chi·∫øu t·ª´ th∆∞ m·ª•c `reference_faces/`. M·ªói ·∫£nh s·∫Ω ƒë∆∞·ª£c tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ƒë·ªÉ so s√°nh v·ªõi khu√¥n m·∫∑t t·ª´ webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044487c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H√†m x·ª≠ l√Ω khu√¥n m·∫∑t ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\n"
     ]
    }
   ],
   "source": [
    "def extract_face(image, required_size=(160, 160)):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t v√† chu·∫©n h√≥a khu√¥n m·∫∑t t·ª´ ·∫£nh\n",
    "    Args:\n",
    "        image: ·∫¢nh ƒë·∫ßu v√†o (numpy array)\n",
    "        required_size: K√≠ch th∆∞·ªõc ƒë·∫ßu ra (160x160 cho FaceNet)\n",
    "    Returns:\n",
    "        face_array: ·∫¢nh khu√¥n m·∫∑t ƒë√£ chu·∫©n h√≥a\n",
    "    \"\"\"\n",
    "    # Ph√°t hi·ªán khu√¥n m·∫∑t b·∫±ng MTCNN\n",
    "    results = detector.detect_faces(image)\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        return None\n",
    "    \n",
    "    # L·∫•y khu√¥n m·∫∑t ƒë·∫ßu ti√™n\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    \n",
    "    # Tr√≠ch xu·∫•t khu√¥n m·∫∑t\n",
    "    face = image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n\n",
    "    face_image = Image.fromarray(face)\n",
    "    face_image = face_image.resize(required_size)\n",
    "    face_array = np.asarray(face_image)\n",
    "    \n",
    "    return face_array\n",
    "\n",
    "def get_embedding(facenet_model, face_pixels):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t embedding vector t·ª´ khu√¥n m·∫∑t\n",
    "    Args:\n",
    "        facenet_model: Model FaceNet\n",
    "        face_pixels: ·∫¢nh khu√¥n m·∫∑t ƒë√£ chu·∫©n h√≥a\n",
    "    Returns:\n",
    "        embedding: Vector ƒë·∫∑c tr∆∞ng c·ªßa khu√¥n m·∫∑t\n",
    "    \"\"\"\n",
    "    # Chu·∫©n h√≥a pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    \n",
    "    # M·ªü r·ªông dimensions\n",
    "    samples = np.expand_dims(face_pixels, axis=0)\n",
    "    \n",
    "    # Tr√≠ch xu·∫•t embedding\n",
    "    embedding = facenet_model.embeddings(samples)\n",
    "    \n",
    "    return embedding[0]\n",
    "\n",
    "print(\"H√†m x·ª≠ l√Ω khu√¥n m·∫∑t ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab617c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o trong th∆∞ m·ª•c 'reference_faces'\n",
      "Vui l√≤ng th√™m ·∫£nh khu√¥n m·∫∑t tham chi·∫øu (format: .jpg, .jpeg, .png)\n"
     ]
    }
   ],
   "source": [
    "# T·∫£i v√† x·ª≠ l√Ω ·∫£nh tham chi·∫øu\n",
    "reference_faces_dir = \"reference_faces\"\n",
    "reference_embeddings = {}\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i\n",
    "if not os.path.exists(reference_faces_dir):\n",
    "    os.makedirs(reference_faces_dir)\n",
    "    print(f\"ƒê√£ t·∫°o th∆∞ m·ª•c '{reference_faces_dir}'. Vui l√≤ng th√™m ·∫£nh khu√¥n m·∫∑t tham chi·∫øu v√†o ƒë√¢y!\")\n",
    "else:\n",
    "    # Load t·∫•t c·∫£ ·∫£nh t·ª´ th∆∞ m·ª•c reference_faces\n",
    "    image_files = [f for f in os.listdir(reference_faces_dir) \n",
    "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\"Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o trong th∆∞ m·ª•c '{reference_faces_dir}'\")\n",
    "        print(\"Vui l√≤ng th√™m ·∫£nh khu√¥n m·∫∑t tham chi·∫øu (format: .jpg, .jpeg, .png)\")\n",
    "    else:\n",
    "        print(f\"ƒêang x·ª≠ l√Ω {len(image_files)} ·∫£nh tham chi·∫øu...\")\n",
    "        \n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(reference_faces_dir, image_file)\n",
    "            \n",
    "            # ƒê·ªçc ·∫£nh\n",
    "            image = cv2.imread(image_path)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Tr√≠ch xu·∫•t khu√¥n m·∫∑t\n",
    "            face = extract_face(image_rgb)\n",
    "            \n",
    "            if face is not None:\n",
    "                # Tr√≠ch xu·∫•t embedding\n",
    "                embedding = get_embedding(facenet_model, face)\n",
    "                \n",
    "                # L∆∞u embedding v·ªõi t√™n (b·ªè extension)\n",
    "                name = os.path.splitext(image_file)[0]\n",
    "                reference_embeddings[name] = embedding\n",
    "                \n",
    "                print(f\"‚úì ƒê√£ x·ª≠ l√Ω: {name}\")\n",
    "            else:\n",
    "                print(f\"‚úó Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t trong: {image_file}\")\n",
    "        \n",
    "        print(f\"\\n=== T·ªïng k·∫øt ===\")\n",
    "        print(f\"S·ªë l∆∞·ª£ng khu√¥n m·∫∑t tham chi·∫øu: {len(reference_embeddings)}\")\n",
    "        print(f\"Danh s√°ch: {list(reference_embeddings.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f0bab",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 4: H√†m so s√°nh khu√¥n m·∫∑t\n",
    "\n",
    "T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa hai embedding vectors s·ª≠ d·ª•ng Cosine Similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdcde311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H√†m so s√°nh khu√¥n m·∫∑t ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine gi·ªØa hai embedding vectors\n",
    "    Args:\n",
    "        embedding1: Vector ƒë·∫∑c tr∆∞ng th·ª© nh·∫•t\n",
    "        embedding2: Vector ƒë·∫∑c tr∆∞ng th·ª© hai\n",
    "    Returns:\n",
    "        similarity: Gi√° tr·ªã ƒë·ªô t∆∞∆°ng ƒë·ªìng (0-1)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(embedding1, embedding2)\n",
    "    norm1 = np.linalg.norm(embedding1)\n",
    "    norm2 = np.linalg.norm(embedding2)\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    return similarity\n",
    "\n",
    "def recognize_face(face_embedding, reference_embeddings, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Nh·∫≠n di·ªán khu√¥n m·∫∑t b·∫±ng c√°ch so s√°nh v·ªõi c√°c embedding tham chi·∫øu\n",
    "    Args:\n",
    "        face_embedding: Embedding c·ªßa khu√¥n m·∫∑t c·∫ßn nh·∫≠n di·ªán\n",
    "        reference_embeddings: Dictionary ch·ª©a c√°c embedding tham chi·∫øu\n",
    "        threshold: Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh kh·ªõp (m·∫∑c ƒë·ªãnh 0.7)\n",
    "    Returns:\n",
    "        name: T√™n ng∆∞·ªùi ƒë∆∞·ª£c nh·∫≠n di·ªán ho·∫∑c \"Unknown\"\n",
    "        max_similarity: ƒê·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t\n",
    "    \"\"\"\n",
    "    if len(reference_embeddings) == 0:\n",
    "        return \"Unknown\", 0.0\n",
    "    \n",
    "    max_similarity = 0.0\n",
    "    recognized_name = \"Unknown\"\n",
    "    \n",
    "    # So s√°nh v·ªõi t·∫•t c·∫£ khu√¥n m·∫∑t tham chi·∫øu\n",
    "    for name, ref_embedding in reference_embeddings.items():\n",
    "        similarity = cosine_similarity(face_embedding, ref_embedding)\n",
    "        \n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            recognized_name = name\n",
    "    \n",
    "    # Ki·ªÉm tra ng∆∞·ª°ng\n",
    "    if max_similarity < threshold:\n",
    "        recognized_name = \"Unknown\"\n",
    "    \n",
    "    return recognized_name, max_similarity\n",
    "\n",
    "print(\"H√†m so s√°nh khu√¥n m·∫∑t ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b921eb9",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 5: Nh·∫≠n di·ªán khu√¥n m·∫∑t theo th·ªùi gian th·ª±c t·ª´ Webcam\n",
    "\n",
    "Ch∆∞∆°ng tr√¨nh ch√≠nh ƒë·ªÉ nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ webcam:\n",
    "- **Space**: D·ª´ng/Ti·∫øp t·ª•c x·ª≠ l√Ω\n",
    "- **Q**: Tho√°t ch∆∞∆°ng tr√¨nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ea7b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è  C·∫¢NH B√ÅO: Kh√¥ng c√≥ khu√¥n m·∫∑t tham chi·∫øu n√†o!\n",
      "Vui l√≤ng th√™m ·∫£nh khu√¥n m·∫∑t v√†o th∆∞ m·ª•c 'reference_faces/' v√† ch·∫°y l·∫°i cell tr∆∞·ªõc ƒë√≥.\n"
     ]
    }
   ],
   "source": [
    "def real_time_face_recognition(reference_embeddings, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Nh·∫≠n di·ªán khu√¥n m·∫∑t theo th·ªùi gian th·ª±c t·ª´ webcam\n",
    "    Args:\n",
    "        reference_embeddings: Dictionary ch·ª©a embedding c·ªßa c√°c khu√¥n m·∫∑t tham chi·∫øu\n",
    "        threshold: Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh kh·ªõp (m·∫∑c ƒë·ªãnh 0.7)\n",
    "    \"\"\"\n",
    "    # Kh·ªüi t·∫°o webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"L·ªói: Kh√¥ng th·ªÉ m·ªü webcam!\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n=== B·∫ÆT ƒê·∫¶U NH·∫¨N DI·ªÜN KHU√îN M·∫∂T ===\")\n",
    "    print(\"Nh·∫•n 'Space' ƒë·ªÉ d·ª´ng/ti·∫øp t·ª•c x·ª≠ l√Ω\")\n",
    "    print(\"Nh·∫•n 'Q' ƒë·ªÉ tho√°t\\n\")\n",
    "    \n",
    "    # Bi·∫øn ƒëi·ªÅu khi·ªÉn\n",
    "    processing = True\n",
    "    frame_count = 0\n",
    "    skip_frames = 2  # X·ª≠ l√Ω m·ªói 2 frame ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"L·ªói: Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ webcam!\")\n",
    "            break\n",
    "        \n",
    "        # L·∫≠t frame theo chi·ªÅu ngang (mirror effect)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Hi·ªÉn th·ªã tr·∫°ng th√°i\n",
    "        status_text = \"Processing\" if processing else \"Paused\"\n",
    "        cv2.putText(frame, f\"Status: {status_text}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # X·ª≠ l√Ω nh·∫≠n di·ªán n·∫øu ƒëang b·∫≠t\n",
    "        if processing and frame_count % skip_frames == 0:\n",
    "            # Chuy·ªÉn ƒë·ªïi BGR sang RGB\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "            results = detector.detect_faces(rgb_frame)\n",
    "            \n",
    "            # X·ª≠ l√Ω t·ª´ng khu√¥n m·∫∑t ph√°t hi·ªán ƒë∆∞·ª£c\n",
    "            for result in results:\n",
    "                # L·∫•y bounding box v√† confidence\n",
    "                x, y, w, h = result['box']\n",
    "                confidence = result['confidence']\n",
    "                \n",
    "                # ƒê·∫£m b·∫£o t·ªça ƒë·ªô kh√¥ng √¢m\n",
    "                x, y = abs(x), abs(y)\n",
    "                \n",
    "                # Tr√≠ch xu·∫•t khu√¥n m·∫∑t\n",
    "                face = rgb_frame[y:y+h, x:x+w]\n",
    "                \n",
    "                try:\n",
    "                    # Resize v√† chu·∫©n h√≥a khu√¥n m·∫∑t\n",
    "                    face_image = Image.fromarray(face)\n",
    "                    face_image = face_image.resize((160, 160))\n",
    "                    face_array = np.asarray(face_image)\n",
    "                    \n",
    "                    # Tr√≠ch xu·∫•t embedding\n",
    "                    face_embedding = get_embedding(facenet_model, face_array)\n",
    "                    \n",
    "                    # Nh·∫≠n di·ªán khu√¥n m·∫∑t\n",
    "                    name, similarity = recognize_face(face_embedding, reference_embeddings, threshold)\n",
    "                    \n",
    "                    # Ch·ªçn m√†u cho bounding box\n",
    "                    if name == \"Unknown\":\n",
    "                        color = (0, 0, 255)  # ƒê·ªè cho Unknown\n",
    "                        label = f\"Unknown ({similarity:.2f})\"\n",
    "                    else:\n",
    "                        color = (0, 255, 0)  # Xanh l√° cho Matched\n",
    "                        label = f\"{name} ({similarity:.2f})\"\n",
    "                    \n",
    "                    # V·∫Ω bounding box\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                    \n",
    "                    # V·∫Ω n·ªÅn cho text\n",
    "                    (text_width, text_height), _ = cv2.getTextSize(label, \n",
    "                                                                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                                                    0.6, 2)\n",
    "                    cv2.rectangle(frame, (x, y-30), (x+text_width, y), color, -1)\n",
    "                    \n",
    "                    # Hi·ªÉn th·ªã t√™n\n",
    "                    cv2.putText(frame, label, (x, y-10),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                    \n",
    "                    # Hi·ªÉn th·ªã confidence c·ªßa MTCNN\n",
    "                    conf_text = f\"Conf: {confidence:.2f}\"\n",
    "                    cv2.putText(frame, conf_text, (x, y+h+20),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"L·ªói x·ª≠ l√Ω khu√¥n m·∫∑t: {e}\")\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n\n",
    "        cv2.putText(frame, \"Press 'Space' to pause/resume, 'Q' to quit\", \n",
    "                   (10, frame.shape[0] - 10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Hi·ªÉn th·ªã frame\n",
    "        cv2.imshow('Real-time Face Recognition', frame)\n",
    "        \n",
    "        # X·ª≠ l√Ω ph√≠m b·∫•m\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q') or key == ord('Q'):\n",
    "            print(\"\\nƒêang tho√°t...\")\n",
    "            break\n",
    "        elif key == ord(' '):  # Space key\n",
    "            processing = not processing\n",
    "            print(f\"X·ª≠ l√Ω: {'B·∫¨T' if processing else 'T·∫ÆT'}\")\n",
    "    \n",
    "    # Gi·∫£i ph√≥ng t√†i nguy√™n\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"ƒê√£ ƒë√≥ng webcam v√† c√°c c·ª≠a s·ªï hi·ªÉn th·ªã!\")\n",
    "\n",
    "# Ch·∫°y ch∆∞∆°ng tr√¨nh nh·∫≠n di·ªán\n",
    "if len(reference_embeddings) > 0:\n",
    "    real_time_face_recognition(reference_embeddings, threshold=0.7)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  C·∫¢NH B√ÅO: Kh√¥ng c√≥ khu√¥n m·∫∑t tham chi·∫øu n√†o!\")\n",
    "    print(\"Vui l√≤ng th√™m ·∫£nh khu√¥n m·∫∑t v√†o th∆∞ m·ª•c 'reference_faces/' v√† ch·∫°y l·∫°i cell tr∆∞·ªõc ƒë√≥.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145237eb",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 6: Thu th·∫≠p th√¥ng tin v√† ƒê√°nh gi√° t·ª´ Webcam\n",
    "\n",
    "Phi√™n b·∫£n n√¢ng cao v·ªõi c√°c t√≠nh nƒÉng:\n",
    "- **Thu th·∫≠p th√¥ng tin**: L∆∞u tr·ªØ c√°c k·∫øt qu·∫£ nh·∫≠n di·ªán\n",
    "- **Hi·ªÉn th·ªã metrics**: FPS, s·ªë khu√¥n m·∫∑t ph√°t hi·ªán, th·ªëng k√™\n",
    "- **Logging**: Ghi l·∫°i l·ªãch s·ª≠ nh·∫≠n di·ªán\n",
    "- **Evaluation Dashboard**: B·∫£ng ƒë√°nh gi√° tr·ª±c quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict, deque\n",
    "from datetime import datetime\n",
    "\n",
    "class FaceRecognitionLogger:\n",
    "    \"\"\"\n",
    "    Class ƒë·ªÉ thu th·∫≠p v√† qu·∫£n l√Ω th√¥ng tin nh·∫≠n di·ªán khu√¥n m·∫∑t\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.recognition_history = []\n",
    "        self.statistics = defaultdict(int)\n",
    "        self.fps_history = deque(maxlen=30)  # L∆∞u 30 FPS g·∫ßn nh·∫•t\n",
    "        self.total_frames = 0\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def log_detection(self, name, similarity, confidence, frame_number):\n",
    "        \"\"\"Ghi l·∫°i th√¥ng tin ph√°t hi·ªán\"\"\"\n",
    "        log_entry = {\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3],\n",
    "            'frame': frame_number,\n",
    "            'name': name,\n",
    "            'similarity': similarity,\n",
    "            'confidence': confidence,\n",
    "            'matched': name != \"Unknown\"\n",
    "        }\n",
    "        self.recognition_history.append(log_entry)\n",
    "        self.statistics[name] += 1\n",
    "        \n",
    "    def update_fps(self, fps):\n",
    "        \"\"\"C·∫≠p nh·∫≠t FPS\"\"\"\n",
    "        self.fps_history.append(fps)\n",
    "        \n",
    "    def get_avg_fps(self):\n",
    "        \"\"\"T√≠nh FPS trung b√¨nh\"\"\"\n",
    "        if len(self.fps_history) > 0:\n",
    "            return sum(self.fps_history) / len(self.fps_history)\n",
    "        return 0\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        \"\"\"L·∫•y th·ªëng k√™\"\"\"\n",
    "        total_detections = sum(self.statistics.values())\n",
    "        matched = sum(count for name, count in self.statistics.items() if name != \"Unknown\")\n",
    "        unknown = self.statistics.get(\"Unknown\", 0)\n",
    "        \n",
    "        runtime = time.time() - self.start_time\n",
    "        \n",
    "        return {\n",
    "            'total_frames': self.total_frames,\n",
    "            'total_detections': total_detections,\n",
    "            'matched_faces': matched,\n",
    "            'unknown_faces': unknown,\n",
    "            'unique_persons': len([k for k in self.statistics.keys() if k != \"Unknown\"]),\n",
    "            'avg_fps': self.get_avg_fps(),\n",
    "            'runtime': runtime,\n",
    "            'detection_rate': matched / total_detections * 100 if total_detections > 0 else 0\n",
    "        }\n",
    "    \n",
    "    def get_recent_logs(self, n=10):\n",
    "        \"\"\"L·∫•y n log g·∫ßn nh·∫•t\"\"\"\n",
    "        return self.recognition_history[-n:] if len(self.recognition_history) >= n else self.recognition_history\n",
    "    \n",
    "    def save_to_file(self, filename='recognition_log.txt'):\n",
    "        \"\"\"L∆∞u log v√†o file\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"=== FACE RECOGNITION LOG ===\\n\\n\")\n",
    "            stats = self.get_statistics()\n",
    "            f.write(f\"Total Frames: {stats['total_frames']}\\n\")\n",
    "            f.write(f\"Total Detections: {stats['total_detections']}\\n\")\n",
    "            f.write(f\"Matched Faces: {stats['matched_faces']}\\n\")\n",
    "            f.write(f\"Unknown Faces: {stats['unknown_faces']}\\n\")\n",
    "            f.write(f\"Detection Rate: {stats['detection_rate']:.2f}%\\n\")\n",
    "            f.write(f\"Average FPS: {stats['avg_fps']:.2f}\\n\")\n",
    "            f.write(f\"Runtime: {stats['runtime']:.2f}s\\n\\n\")\n",
    "            \n",
    "            f.write(\"=== RECOGNITION HISTORY ===\\n\")\n",
    "            for entry in self.recognition_history:\n",
    "                f.write(f\"{entry['timestamp']} | Frame {entry['frame']} | {entry['name']} \"\n",
    "                       f\"| Sim: {entry['similarity']:.3f} | Conf: {entry['confidence']:.3f}\\n\")\n",
    "        print(f\"Log ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {filename}\")\n",
    "\n",
    "print(\"FaceRecognitionLogger ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_evaluation_dashboard(frame, logger, detected_faces_count):\n",
    "    \"\"\"\n",
    "    V·∫Ω b·∫£ng ƒë√°nh gi√° (dashboard) l√™n frame\n",
    "    Args:\n",
    "        frame: Frame video\n",
    "        logger: FaceRecognitionLogger instance\n",
    "        detected_faces_count: S·ªë khu√¥n m·∫∑t ph√°t hi·ªán trong frame hi·ªán t·∫°i\n",
    "    \"\"\"\n",
    "    stats = logger.get_statistics()\n",
    "    \n",
    "    # T·∫°o overlay semi-transparent cho dashboard\n",
    "    overlay = frame.copy()\n",
    "    dashboard_height = 200\n",
    "    dashboard_width = 400\n",
    "    \n",
    "    # V·∫Ω n·ªÅn dashboard (g√≥c tr√™n b√™n ph·∫£i)\n",
    "    x_start = frame.shape[1] - dashboard_width - 10\n",
    "    y_start = 10\n",
    "    cv2.rectangle(overlay, (x_start, y_start), \n",
    "                 (x_start + dashboard_width, y_start + dashboard_height),\n",
    "                 (0, 0, 0), -1)\n",
    "    \n",
    "    # Blend overlay v·ªõi frame g·ªëc\n",
    "    alpha = 0.7\n",
    "    frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
    "    \n",
    "    # ƒê·ªãnh nghƒ©a v·ªã tr√≠ text\n",
    "    text_x = x_start + 10\n",
    "    text_y = y_start + 25\n",
    "    line_height = 25\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "    font_thickness = 1\n",
    "    \n",
    "    # Ti√™u ƒë·ªÅ\n",
    "    cv2.putText(frame, \"=== EVALUATION DASHBOARD ===\", \n",
    "               (text_x, text_y), font, 0.6, (0, 255, 255), 2)\n",
    "    text_y += line_height + 5\n",
    "    \n",
    "    # Th√¥ng tin th·ªùi gian th·ª±c\n",
    "    cv2.putText(frame, f\"FPS: {stats['avg_fps']:.1f}\", \n",
    "               (text_x, text_y), font, font_scale, (0, 255, 0), font_thickness)\n",
    "    text_y += line_height\n",
    "    \n",
    "    cv2.putText(frame, f\"Faces in Frame: {detected_faces_count}\", \n",
    "               (text_x, text_y), font, font_scale, (255, 255, 0), font_thickness)\n",
    "    text_y += line_height\n",
    "    \n",
    "    cv2.putText(frame, f\"Runtime: {stats['runtime']:.1f}s\", \n",
    "               (text_x, text_y), font, font_scale, (255, 255, 255), font_thickness)\n",
    "    text_y += line_height + 5\n",
    "    \n",
    "    # ƒê∆∞·ªùng ph√¢n c√°ch\n",
    "    cv2.line(frame, (text_x, text_y), (x_start + dashboard_width - 10, text_y), \n",
    "            (100, 100, 100), 1)\n",
    "    text_y += 10\n",
    "    \n",
    "    # Th·ªëng k√™ t·ªïng h·ª£p\n",
    "    cv2.putText(frame, f\"Total Frames: {stats['total_frames']}\", \n",
    "               (text_x, text_y), font, font_scale, (200, 200, 200), font_thickness)\n",
    "    text_y += line_height\n",
    "    \n",
    "    cv2.putText(frame, f\"Total Detections: {stats['total_detections']}\", \n",
    "               (text_x, text_y), font, font_scale, (200, 200, 200), font_thickness)\n",
    "    text_y += line_height\n",
    "    \n",
    "    cv2.putText(frame, f\"Matched: {stats['matched_faces']}\", \n",
    "               (text_x, text_y), font, font_scale, (0, 255, 0), font_thickness)\n",
    "    text_y += line_height\n",
    "    \n",
    "    cv2.putText(frame, f\"Unknown: {stats['unknown_faces']}\", \n",
    "               (text_x, text_y), font, font_scale, (0, 0, 255), font_thickness)\n",
    "    text_y += line_height\n",
    "    \n",
    "    cv2.putText(frame, f\"Detection Rate: {stats['detection_rate']:.1f}%\", \n",
    "               (text_x, text_y), font, font_scale, (255, 165, 0), font_thickness)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "print(\"H√†m v·∫Ω dashboard ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b3cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_face_recognition_with_logging(reference_embeddings, threshold=0.7, save_log=True):\n",
    "    \"\"\"\n",
    "    Nh·∫≠n di·ªán khu√¥n m·∫∑t n√¢ng cao v·ªõi thu th·∫≠p th√¥ng tin v√† hi·ªÉn th·ªã ƒë√°nh gi√°\n",
    "    Args:\n",
    "        reference_embeddings: Dictionary ch·ª©a embedding c·ªßa c√°c khu√¥n m·∫∑t tham chi·∫øu\n",
    "        threshold: Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh kh·ªõp (m·∫∑c ƒë·ªãnh 0.7)\n",
    "        save_log: L∆∞u log v√†o file khi k·∫øt th√∫c (m·∫∑c ƒë·ªãnh True)\n",
    "    \"\"\"\n",
    "    # Kh·ªüi t·∫°o logger\n",
    "    logger = FaceRecognitionLogger()\n",
    "    \n",
    "    # Kh·ªüi t·∫°o webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"L·ªói: Kh√¥ng th·ªÉ m·ªü webcam!\")\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n=== B·∫ÆT ƒê·∫¶U NH·∫¨N DI·ªÜN KHU√îN M·∫∂T V·ªöI LOGGING ===\")\n",
    "    print(\"Nh·∫•n 'Space' ƒë·ªÉ d·ª´ng/ti·∫øp t·ª•c x·ª≠ l√Ω\")\n",
    "    print(\"Nh·∫•n 'S' ƒë·ªÉ l∆∞u log ngay l·∫≠p t·ª©c\")\n",
    "    print(\"Nh·∫•n 'D' ƒë·ªÉ b·∫≠t/t·∫Øt dashboard\")\n",
    "    print(\"Nh·∫•n 'L' ƒë·ªÉ in log g·∫ßn nh·∫•t\")\n",
    "    print(\"Nh·∫•n 'Q' ƒë·ªÉ tho√°t\\n\")\n",
    "    \n",
    "    # Bi·∫øn ƒëi·ªÅu khi·ªÉn\n",
    "    processing = True\n",
    "    show_dashboard = True\n",
    "    frame_count = 0\n",
    "    skip_frames = 2\n",
    "    \n",
    "    # Bi·∫øn cho FPS calculation\n",
    "    fps = 0\n",
    "    frame_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        loop_start = time.time()\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"L·ªói: Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ webcam!\")\n",
    "            break\n",
    "        \n",
    "        # L·∫≠t frame theo chi·ªÅu ngang\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        logger.total_frames += 1\n",
    "        frame_count += 1\n",
    "        \n",
    "        # Bi·∫øn ƒë·∫øm s·ªë khu√¥n m·∫∑t trong frame hi·ªán t·∫°i\n",
    "        detected_faces_count = 0\n",
    "        \n",
    "        # Hi·ªÉn th·ªã tr·∫°ng th√°i processing\n",
    "        status_color = (0, 255, 0) if processing else (0, 165, 255)\n",
    "        status_text = \"PROCESSING\" if processing else \"PAUSED\"\n",
    "        cv2.putText(frame, f\"Status: {status_text}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)\n",
    "        \n",
    "        # X·ª≠ l√Ω nh·∫≠n di·ªán\n",
    "        if processing and frame_count % skip_frames == 0:\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "            detection_start = time.time()\n",
    "            results = detector.detect_faces(rgb_frame)\n",
    "            detection_time = time.time() - detection_start\n",
    "            \n",
    "            detected_faces_count = len(results)\n",
    "            \n",
    "            # X·ª≠ l√Ω t·ª´ng khu√¥n m·∫∑t\n",
    "            for idx, result in enumerate(results):\n",
    "                x, y, w, h = result['box']\n",
    "                confidence = result['confidence']\n",
    "                \n",
    "                x, y = abs(x), abs(y)\n",
    "                face = rgb_frame[y:y+h, x:x+w]\n",
    "                \n",
    "                try:\n",
    "                    # Tr√≠ch xu·∫•t embedding\n",
    "                    face_image = Image.fromarray(face)\n",
    "                    face_image = face_image.resize((160, 160))\n",
    "                    face_array = np.asarray(face_image)\n",
    "                    \n",
    "                    embedding_start = time.time()\n",
    "                    face_embedding = get_embedding(facenet_model, face_array)\n",
    "                    embedding_time = time.time() - embedding_start\n",
    "                    \n",
    "                    # Nh·∫≠n di·ªán\n",
    "                    recognition_start = time.time()\n",
    "                    name, similarity = recognize_face(face_embedding, reference_embeddings, threshold)\n",
    "                    recognition_time = time.time() - recognition_start\n",
    "                    \n",
    "                    # Log th√¥ng tin\n",
    "                    logger.log_detection(name, similarity, confidence, frame_count)\n",
    "                    \n",
    "                    # V·∫Ω k·∫øt qu·∫£\n",
    "                    if name == \"Unknown\":\n",
    "                        color = (0, 0, 255)\n",
    "                        label = f\"Unknown ({similarity:.2f})\"\n",
    "                    else:\n",
    "                        color = (0, 255, 0)\n",
    "                        label = f\"{name} ({similarity:.2f})\"\n",
    "                    \n",
    "                    # V·∫Ω bounding box v·ªõi hi·ªáu ·ª©ng\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3)\n",
    "                    \n",
    "                    # V·∫Ω c√°c g√≥c c·ªßa bounding box (corner markers)\n",
    "                    corner_length = 20\n",
    "                    corner_thickness = 3\n",
    "                    # G√≥c tr√™n tr√°i\n",
    "                    cv2.line(frame, (x, y), (x + corner_length, y), color, corner_thickness)\n",
    "                    cv2.line(frame, (x, y), (x, y + corner_length), color, corner_thickness)\n",
    "                    # G√≥c tr√™n ph·∫£i\n",
    "                    cv2.line(frame, (x+w, y), (x+w - corner_length, y), color, corner_thickness)\n",
    "                    cv2.line(frame, (x+w, y), (x+w, y + corner_length), color, corner_thickness)\n",
    "                    # G√≥c d∆∞·ªõi tr√°i\n",
    "                    cv2.line(frame, (x, y+h), (x + corner_length, y+h), color, corner_thickness)\n",
    "                    cv2.line(frame, (x, y+h), (x, y+h - corner_length), color, corner_thickness)\n",
    "                    # G√≥c d∆∞·ªõi ph·∫£i\n",
    "                    cv2.line(frame, (x+w, y+h), (x+w - corner_length, y+h), color, corner_thickness)\n",
    "                    cv2.line(frame, (x+w, y+h), (x+w, y+h - corner_length), color, corner_thickness)\n",
    "                    \n",
    "                    # V·∫Ω n·ªÅn cho label\n",
    "                    (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                        label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                    cv2.rectangle(frame, (x, y-35), (x+text_width+10, y), color, -1)\n",
    "                    \n",
    "                    # V·∫Ω label\n",
    "                    cv2.putText(frame, label, (x+5, y-10),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                    \n",
    "                    # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt\n",
    "                    info_y = y + h + 20\n",
    "                    cv2.putText(frame, f\"Conf: {confidence:.2f}\", (x, info_y),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "                    \n",
    "                    # Hi·ªÉn th·ªã th·ªùi gian x·ª≠ l√Ω (g√≥c d∆∞·ªõi b√™n ph·∫£i c·ªßa box)\n",
    "                    total_process_time = detection_time + embedding_time + recognition_time\n",
    "                    cv2.putText(frame, f\"{total_process_time*1000:.0f}ms\", \n",
    "                               (x+w-60, info_y),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"L·ªói x·ª≠ l√Ω khu√¥n m·∫∑t #{idx+1}: {e}\")\n",
    "        \n",
    "        # T√≠nh FPS\n",
    "        frame_time_elapsed = time.time() - loop_start\n",
    "        if frame_time_elapsed > 0:\n",
    "            fps = 1.0 / frame_time_elapsed\n",
    "            logger.update_fps(fps)\n",
    "        \n",
    "        # V·∫Ω dashboard n·∫øu ƒë∆∞·ª£c b·∫≠t\n",
    "        if show_dashboard:\n",
    "            frame = draw_evaluation_dashboard(frame, logger, detected_faces_count)\n",
    "        \n",
    "        # Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n\n",
    "        cv2.putText(frame, \"Press: [Space]Pause [S]Save [D]Dashboard [L]Logs [Q]Quit\", \n",
    "                   (10, frame.shape[0] - 10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Hi·ªÉn th·ªã frame\n",
    "        cv2.imshow('Advanced Face Recognition', frame)\n",
    "        \n",
    "        # X·ª≠ l√Ω ph√≠m b·∫•m\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q') or key == ord('Q'):\n",
    "            print(\"\\nüõë ƒêang tho√°t...\")\n",
    "            break\n",
    "        elif key == ord(' '):\n",
    "            processing = not processing\n",
    "            print(f\"‚èØÔ∏è  X·ª≠ l√Ω: {'B·∫¨T' if processing else 'T·∫ÆT'}\")\n",
    "        elif key == ord('s') or key == ord('S'):\n",
    "            logger.save_to_file(f'recognition_log_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt')\n",
    "        elif key == ord('d') or key == ord('D'):\n",
    "            show_dashboard = not show_dashboard\n",
    "            print(f\"üìä Dashboard: {'B·∫¨T' if show_dashboard else 'T·∫ÆT'}\")\n",
    "        elif key == ord('l') or key == ord('L'):\n",
    "            print(\"\\nüìã === 10 LOG G·∫¶N NH·∫§T ===\")\n",
    "            recent_logs = logger.get_recent_logs(10)\n",
    "            for log in recent_logs:\n",
    "                status = \"‚úì\" if log['matched'] else \"‚úó\"\n",
    "                print(f\"{status} {log['timestamp']} | {log['name']} | Sim: {log['similarity']:.3f}\")\n",
    "            print()\n",
    "    \n",
    "    # Gi·∫£i ph√≥ng t√†i nguy√™n\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Hi·ªÉn th·ªã th·ªëng k√™ cu·ªëi c√πng\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìä TH·ªêNG K√ä CU·ªêI C√ôNG\")\n",
    "    print(\"=\"*50)\n",
    "    stats = logger.get_statistics()\n",
    "    print(f\"T·ªïng s·ªë frames: {stats['total_frames']}\")\n",
    "    print(f\"T·ªïng s·ªë ph√°t hi·ªán: {stats['total_detections']}\")\n",
    "    print(f\"Khu√¥n m·∫∑t kh·ªõp: {stats['matched_faces']}\")\n",
    "    print(f\"Khu√¥n m·∫∑t l·∫°: {stats['unknown_faces']}\")\n",
    "    print(f\"T·ª∑ l·ªá nh·∫≠n di·ªán: {stats['detection_rate']:.2f}%\")\n",
    "    print(f\"FPS trung b√¨nh: {stats['avg_fps']:.2f}\")\n",
    "    print(f\"Th·ªùi gian ch·∫°y: {stats['runtime']:.2f}s\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # L∆∞u log n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu\n",
    "    if save_log:\n",
    "        logger.save_to_file(f'recognition_log_final_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt')\n",
    "    \n",
    "    return logger\n",
    "\n",
    "# Ch·∫°y ch∆∞∆°ng tr√¨nh n√¢ng cao\n",
    "if len(reference_embeddings) > 0:\n",
    "    recognition_logger = advanced_face_recognition_with_logging(\n",
    "        reference_embeddings, \n",
    "        threshold=0.7,\n",
    "        save_log=True\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  C·∫¢NH B√ÅO: Kh√¥ng c√≥ khu√¥n m·∫∑t tham chi·∫øu n√†o!\")\n",
    "    print(\"Vui l√≤ng th√™m ·∫£nh khu√¥n m·∫∑t v√†o th∆∞ m·ª•c 'reference_faces/' v√† ch·∫°y l·∫°i c√°c cell tr∆∞·ªõc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425858a",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 7: Ph√¢n t√≠ch Log v√† Visualization\n",
    "\n",
    "Ph√¢n t√≠ch d·ªØ li·ªáu ƒë√£ thu th·∫≠p t·ª´ qu√° tr√¨nh nh·∫≠n di·ªán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_recognition_logs(logger):\n",
    "    \"\"\"\n",
    "    Ph√¢n t√≠ch v√† hi·ªÉn th·ªã k·∫øt qu·∫£ t·ª´ log nh·∫≠n di·ªán\n",
    "    Args:\n",
    "        logger: FaceRecognitionLogger instance\n",
    "    \"\"\"\n",
    "    if logger is None or len(logger.recognition_history) == 0:\n",
    "        print(\"‚ö†Ô∏è  Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch!\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä PH√ÇN T√çCH CHI TI·∫æT LOG NH·∫¨N DI·ªÜN KHU√îN M·∫∂T\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 1. Th·ªëng k√™ theo ng∆∞·ªùi\n",
    "    print(\"\\n1Ô∏è‚É£  TH·ªêNG K√ä THEO NG∆Ø·ªúI:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'T√™n':<20} {'S·ªë l·∫ßn xu·∫•t hi·ªán':<20} {'T·ª∑ l·ªá':<20}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    total_detections = sum(logger.statistics.values())\n",
    "    sorted_stats = sorted(logger.statistics.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for name, count in sorted_stats:\n",
    "        percentage = (count / total_detections * 100) if total_detections > 0 else 0\n",
    "        icon = \"‚ùì\" if name == \"Unknown\" else \"‚úì\"\n",
    "        print(f\"{icon} {name:<18} {count:<20} {percentage:>6.2f}%\")\n",
    "    \n",
    "    # 2. Ph√¢n t√≠ch ƒë·ªô t∆∞∆°ng ƒë·ªìng\n",
    "    print(\"\\n2Ô∏è‚É£  PH√ÇN T√çCH ƒê·ªò T∆Ø∆†NG ƒê·ªíNG:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    matched_logs = [log for log in logger.recognition_history if log['matched']]\n",
    "    unknown_logs = [log for log in logger.recognition_history if not log['matched']]\n",
    "    \n",
    "    if matched_logs:\n",
    "        matched_similarities = [log['similarity'] for log in matched_logs]\n",
    "        print(f\"Khu√¥n m·∫∑t KH·ªöP:\")\n",
    "        print(f\"  ‚Ä¢ S·ªë l∆∞·ª£ng: {len(matched_logs)}\")\n",
    "        print(f\"  ‚Ä¢ Similarity trung b√¨nh: {np.mean(matched_similarities):.3f}\")\n",
    "        print(f\"  ‚Ä¢ Similarity cao nh·∫•t: {np.max(matched_similarities):.3f}\")\n",
    "        print(f\"  ‚Ä¢ Similarity th·∫•p nh·∫•t: {np.min(matched_similarities):.3f}\")\n",
    "        print(f\"  ‚Ä¢ ƒê·ªô l·ªách chu·∫©n: {np.std(matched_similarities):.3f}\")\n",
    "    \n",
    "    if unknown_logs:\n",
    "        unknown_similarities = [log['similarity'] for log in unknown_logs]\n",
    "        print(f\"\\nKhu√¥n m·∫∑t L·∫† (Unknown):\")\n",
    "        print(f\"  ‚Ä¢ S·ªë l∆∞·ª£ng: {len(unknown_logs)}\")\n",
    "        print(f\"  ‚Ä¢ Similarity trung b√¨nh: {np.mean(unknown_similarities):.3f}\")\n",
    "        print(f\"  ‚Ä¢ Similarity cao nh·∫•t: {np.max(unknown_similarities):.3f}\")\n",
    "        print(f\"  ‚Ä¢ Similarity th·∫•p nh·∫•t: {np.min(unknown_similarities):.3f}\")\n",
    "    \n",
    "    # 3. Ph√¢n t√≠ch confidence MTCNN\n",
    "    print(\"\\n3Ô∏è‚É£  PH√ÇN T√çCH CONFIDENCE (MTCNN):\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    all_confidences = [log['confidence'] for log in logger.recognition_history]\n",
    "    if all_confidences:\n",
    "        print(f\"Confidence trung b√¨nh: {np.mean(all_confidences):.3f}\")\n",
    "        print(f\"Confidence cao nh·∫•t: {np.max(all_confidences):.3f}\")\n",
    "        print(f\"Confidence th·∫•p nh·∫•t: {np.min(all_confidences):.3f}\")\n",
    "        print(f\"S·ªë ph√°t hi·ªán confidence > 0.95: {sum(1 for c in all_confidences if c > 0.95)}\")\n",
    "        print(f\"S·ªë ph√°t hi·ªán confidence < 0.90: {sum(1 for c in all_confidences if c < 0.90)}\")\n",
    "    \n",
    "    # 4. Ph√¢n t√≠ch hi·ªáu su·∫•t\n",
    "    print(\"\\n4Ô∏è‚É£  PH√ÇN T√çCH HI·ªÜU SU·∫§T:\")\n",
    "    print(\"-\" * 70)\n",
    "    stats = logger.get_statistics()\n",
    "    print(f\"FPS trung b√¨nh: {stats['avg_fps']:.2f}\")\n",
    "    print(f\"T·ªïng frames x·ª≠ l√Ω: {stats['total_frames']}\")\n",
    "    print(f\"T·ªïng th·ªùi gian: {stats['runtime']:.2f}s\")\n",
    "    print(f\"Frames/gi√¢y: {stats['total_frames'] / stats['runtime']:.2f}\")\n",
    "    \n",
    "    # 5. Timeline - Nh·∫≠n di·ªán theo th·ªùi gian\n",
    "    print(\"\\n5Ô∏è‚É£  TIMELINE - 10 NH·∫¨N DI·ªÜN ƒê·∫¶U TI√äN:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Th·ªùi gian':<24} {'Frame':<8} {'T√™n':<15} {'Similarity':<12} {'Conf':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for log in logger.recognition_history[:10]:\n",
    "        icon = \"‚úì\" if log['matched'] else \"‚úó\"\n",
    "        print(f\"{log['timestamp']:<24} {log['frame']:<8} {icon} {log['name']:<13} \"\n",
    "              f\"{log['similarity']:.3f}        {log['confidence']:.3f}\")\n",
    "    \n",
    "    print(\"\\n6Ô∏è‚É£  TIMELINE - 10 NH·∫¨N DI·ªÜN CU·ªêI C√ôNG:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Th·ªùi gian':<24} {'Frame':<8} {'T√™n':<15} {'Similarity':<12} {'Conf':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for log in logger.recognition_history[-10:]:\n",
    "        icon = \"‚úì\" if log['matched'] else \"‚úó\"\n",
    "        print(f\"{log['timestamp']:<24} {log['frame']:<8} {icon} {log['name']:<13} \"\n",
    "              f\"{log['similarity']:.3f}        {log['confidence']:.3f}\")\n",
    "    \n",
    "    # 7. ƒê√°nh gi√° ng∆∞·ª°ng\n",
    "    print(\"\\n7Ô∏è‚É£  ƒê√ÅNH GI√Å NG∆Ø·ª†NG THRESHOLD = 0.7:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # C√°c tr∆∞·ªùng h·ª£p g·∫ßn ng∆∞·ª°ng\n",
    "    near_threshold = [log for log in logger.recognition_history \n",
    "                     if 0.65 <= log['similarity'] <= 0.75]\n",
    "    \n",
    "    if near_threshold:\n",
    "        print(f\"S·ªë tr∆∞·ªùng h·ª£p g·∫ßn ng∆∞·ª°ng (0.65-0.75): {len(near_threshold)}\")\n",
    "        print(f\"C√≥ th·ªÉ c·∫ßn ƒëi·ªÅu ch·ªânh threshold ƒë·ªÉ t·ªëi ∆∞u!\")\n",
    "        \n",
    "        matched_near = [log for log in near_threshold if log['matched']]\n",
    "        unknown_near = [log for log in near_threshold if not log['matched']]\n",
    "        \n",
    "        print(f\"  ‚Ä¢ Matched g·∫ßn ng∆∞·ª°ng: {len(matched_near)}\")\n",
    "        print(f\"  ‚Ä¢ Unknown g·∫ßn ng∆∞·ª°ng: {len(unknown_near)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ HO√ÄN TH√ÄNH PH√ÇN T√çCH!\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Ch·∫°y ph√¢n t√≠ch n·∫øu c√≥ logger t·ª´ l·∫ßn ch·∫°y tr∆∞·ªõc\n",
    "if 'recognition_logger' in locals() and recognition_logger is not None:\n",
    "    analyze_recognition_logs(recognition_logger)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Ch·∫°y cell nh·∫≠n di·ªán khu√¥n m·∫∑t tr∆∞·ªõc ƒë·ªÉ c√≥ d·ªØ li·ªáu ph√¢n t√≠ch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c44f7",
   "metadata": {},
   "source": [
    "## T·ªïng k·∫øt v√† Gi·∫£i th√≠ch c√°c t√≠nh nƒÉng m·ªõi\n",
    "\n",
    "### üéØ C√°c t√≠nh nƒÉng ƒë√£ th√™m:\n",
    "\n",
    "#### 1. **FaceRecognitionLogger Class**\n",
    "- Thu th·∫≠p v√† l∆∞u tr·ªØ t·∫•t c·∫£ th√¥ng tin nh·∫≠n di·ªán\n",
    "- T√≠nh to√°n FPS v√† th·ªëng k√™ theo th·ªùi gian th·ª±c\n",
    "- L∆∞u log v√†o file text ƒë·ªÉ ph√¢n t√≠ch sau\n",
    "\n",
    "#### 2. **Evaluation Dashboard**\n",
    "Hi·ªÉn th·ªã tr·ª±c ti·∫øp tr√™n video:\n",
    "- **FPS**: Frames per second\n",
    "- **Faces in Frame**: S·ªë khu√¥n m·∫∑t hi·ªán t·∫°i\n",
    "- **Runtime**: Th·ªùi gian ch·∫°y\n",
    "- **Total Frames**: T·ªïng s·ªë frames ƒë√£ x·ª≠ l√Ω\n",
    "- **Total Detections**: T·ªïng s·ªë l·∫ßn ph√°t hi·ªán khu√¥n m·∫∑t\n",
    "- **Matched/Unknown**: Th·ªëng k√™ k·∫øt qu·∫£ nh·∫≠n di·ªán\n",
    "- **Detection Rate**: T·ª∑ l·ªá nh·∫≠n di·ªán th√†nh c√¥ng (%)\n",
    "\n",
    "#### 3. **Enhanced Visualization**\n",
    "- Bounding box v·ªõi corner markers (g√≥c bo tr√≤n)\n",
    "- Hi·ªÉn th·ªã th·ªùi gian x·ª≠ l√Ω cho m·ªói khu√¥n m·∫∑t (ms)\n",
    "- M√†u s·∫Øc ph√¢n bi·ªát: Xanh (Matched), ƒê·ªè (Unknown)\n",
    "- Th√¥ng tin chi ti·∫øt: Similarity score, Confidence\n",
    "\n",
    "#### 4. **Interactive Controls**\n",
    "- **Space**: T·∫°m d·ª´ng/Ti·∫øp t·ª•c x·ª≠ l√Ω\n",
    "- **S**: L∆∞u log ngay l·∫≠p t·ª©c\n",
    "- **D**: B·∫≠t/T·∫Øt dashboard\n",
    "- **L**: Xem 10 log g·∫ßn nh·∫•t trong console\n",
    "- **Q**: Tho√°t v√† hi·ªÉn th·ªã th·ªëng k√™ t·ªïng h·ª£p\n",
    "\n",
    "#### 5. **Log Analysis Function**\n",
    "Ph√¢n t√≠ch chi ti·∫øt sau khi k·∫øt th√∫c:\n",
    "- Th·ªëng k√™ theo t·ª´ng ng∆∞·ªùi\n",
    "- Ph√¢n t√≠ch ƒë·ªô t∆∞∆°ng ƒë·ªìng (similarity distribution)\n",
    "- Ph√¢n t√≠ch confidence c·ªßa MTCNN\n",
    "- ƒê√°nh gi√° hi·ªáu su·∫•t (FPS, runtime)\n",
    "- Timeline nh·∫≠n di·ªán\n",
    "- ƒê·ªÅ xu·∫•t ƒëi·ªÅu ch·ªânh threshold\n",
    "\n",
    "### üìä C√°ch s·ª≠ d·ª•ng:\n",
    "\n",
    "1. **Ch·∫°y cell nh·∫≠n di·ªán n√¢ng cao** (Cell 19) - S·∫Ω b·∫≠t webcam v·ªõi ƒë·∫ßy ƒë·ªß t√≠nh nƒÉng\n",
    "2. **Quan s√°t dashboard** ·ªü g√≥c tr√™n b√™n ph·∫£i ƒë·ªÉ xem metrics\n",
    "3. **S·ª≠ d·ª•ng ph√≠m t·∫Øt** ƒë·ªÉ ƒëi·ªÅu khi·ªÉn\n",
    "4. **Sau khi tho√°t**, xem th·ªëng k√™ t·ªïng h·ª£p ƒë∆∞·ª£c in ra\n",
    "5. **Ch·∫°y cell ph√¢n t√≠ch** (Cell 21) ƒë·ªÉ xem ph√¢n t√≠ch chi ti·∫øt\n",
    "\n",
    "### üí° L·ª£i √≠ch:\n",
    "\n",
    "- **Thu th·∫≠p d·ªØ li·ªáu**: L∆∞u tr·ªØ ƒë·∫ßy ƒë·ªß th√¥ng tin ƒë·ªÉ ph√¢n t√≠ch\n",
    "- **ƒê√°nh gi√° hi·ªáu su·∫•t**: Xem FPS, detection rate\n",
    "- **T·ªëi ∆∞u threshold**: Ph√¢n t√≠ch ƒë·ªÉ ƒëi·ªÅu ch·ªânh ng∆∞·ª°ng 0.7\n",
    "- **Debugging**: X√°c ƒë·ªãnh c√°c tr∆∞·ªùng h·ª£p nh·∫≠n di·ªán sai\n",
    "- **B√°o c√°o**: Export log ra file text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8c30d6",
   "metadata": {},
   "source": [
    "## H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng\n",
    "\n",
    "### B∆∞·ªõc chu·∫©n b·ªã:\n",
    "1. **C√†i ƒë·∫∑t th∆∞ vi·ªán**: Ch·∫°y cell ƒë·∫ßu ti√™n ƒë·ªÉ c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "2. **Chu·∫©n b·ªã ·∫£nh tham chi·∫øu**: \n",
    "   - T·∫°o th∆∞ m·ª•c `reference_faces/` (n·∫øu ch∆∞a c√≥)\n",
    "   - Th√™m ·∫£nh khu√¥n m·∫∑t c·ªßa ng∆∞·ªùi c·∫ßn nh·∫≠n di·ªán v√†o th∆∞ m·ª•c n√†y\n",
    "   - T√™n file s·∫Ω l√† t√™n hi·ªÉn th·ªã (v√≠ d·ª•: `john.jpg` ‚Üí \"john\")\n",
    "   - ƒê·ªãnh d·∫°ng h·ªó tr·ª£: `.jpg`, `.jpeg`, `.png`\n",
    "\n",
    "### C√°ch s·ª≠ d·ª•ng:\n",
    "1. Ch·∫°y t·∫•t c·∫£ c√°c cell theo th·ª© t·ª±\n",
    "2. Webcam s·∫Ω t·ª± ƒë·ªông b·∫≠t l√™n\n",
    "3. **Ph√≠m t·∫Øt**:\n",
    "   - **Space**: T·∫°m d·ª´ng/Ti·∫øp t·ª•c x·ª≠ l√Ω\n",
    "   - **Q**: Tho√°t ch∆∞∆°ng tr√¨nh\n",
    "\n",
    "### Ng∆∞·ª°ng nh·∫≠n di·ªán:\n",
    "- **Similarity > 0.7**: Hi·ªÉn th·ªã t√™n ng∆∞·ªùi (Matched) - M√†u xanh l√°\n",
    "- **Similarity < 0.7**: Hi·ªÉn th·ªã \"Unknown\" - M√†u ƒë·ªè\n",
    "\n",
    "### Th√¥ng s·ªë hi·ªÉn th·ªã:\n",
    "- **T√™n ng∆∞·ªùi/Unknown**: K·∫øt qu·∫£ nh·∫≠n di·ªán\n",
    "- **Similarity score**: ƒê·ªô t∆∞∆°ng ƒë·ªìng (0-1)\n",
    "- **Confidence**: ƒê·ªô tin c·∫≠y ph√°t hi·ªán khu√¥n m·∫∑t c·ªßa MTCNN\n",
    "\n",
    "### L∆∞u √Ω:\n",
    "- FaceNet y√™u c·∫ßu ·∫£nh khu√¥n m·∫∑t c√≥ k√≠ch th∆∞·ªõc 160x160 pixels\n",
    "- MTCNN t·ª± ƒë·ªông ph√°t hi·ªán v√† crop khu√¥n m·∫∑t\n",
    "- Ch∆∞∆°ng tr√¨nh x·ª≠ l√Ω m·ªói 2 frame ƒë·ªÉ t·ªëi ∆∞u hi·ªáu su·∫•t\n",
    "- ƒê·∫£m b·∫£o webcam ƒë∆∞·ª£c k·∫øt n·ªëi tr∆∞·ªõc khi ch·∫°y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94c7af4",
   "metadata": {},
   "source": [
    "## Gi·∫£i th√≠ch k·ªπ thu·∫≠t\n",
    "\n",
    "### 1. MTCNN (Multi-task Cascaded Convolutional Networks)\n",
    "- **Ch·ª©c nƒÉng**: Ph√°t hi·ªán khu√¥n m·∫∑t v√† c√°c ƒëi·ªÉm ƒë·∫∑c tr∆∞ng (landmarks)\n",
    "- **∆Øu ƒëi·ªÉm**: \n",
    "  - ƒê·ªô ch√≠nh x√°c cao\n",
    "  - Ph√°t hi·ªán ƒë∆∞·ª£c nhi·ªÅu khu√¥n m·∫∑t trong m·ªôt ·∫£nh\n",
    "  - X·ª≠ l√Ω t·ªët c√°c tr∆∞·ªùng h·ª£p khu√¥n m·∫∑t nghi√™ng, ch·∫•t l∆∞·ª£ng ·∫£nh th·∫•p\n",
    "\n",
    "### 2. FaceNet\n",
    "- **Ch·ª©c nƒÉng**: Tr√≠ch xu·∫•t embedding vector (128 ho·∫∑c 512 chi·ªÅu) t·ª´ khu√¥n m·∫∑t\n",
    "- **Nguy√™n l√Ω**: \n",
    "  - M·ªói khu√¥n m·∫∑t ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng m·ªôt vector s·ªë\n",
    "  - C√°c khu√¥n m·∫∑t gi·ªëng nhau c√≥ vector g·∫ßn nhau trong kh√¥ng gian nhi·ªÅu chi·ªÅu\n",
    "- **K√≠ch th∆∞·ªõc ƒë·∫ßu v√†o**: 160x160x3 pixels\n",
    "\n",
    "### 3. Cosine Similarity\n",
    "- **C√¥ng th·ª©c**: $\\text{similarity} = \\frac{A \\cdot B}{||A|| \\times ||B||}$\n",
    "- **Gi√° tr·ªã**: \n",
    "  - 1.0 = ho√†n to√†n gi·ªëng nhau\n",
    "  - 0.0 = kh√¥ng c√≥ ƒëi·ªÉm chung\n",
    "  - -1.0 = ho√†n to√†n ƒë·ªëi l·∫≠p\n",
    "- **Ng∆∞·ª°ng 0.7**: C√¢n b·∫±ng gi·ªØa ƒë·ªô ch√≠nh x√°c v√† kh·∫£ nƒÉng nh·∫≠n di·ªán\n",
    "\n",
    "### 4. Lu·ªìng x·ª≠ l√Ω:\n",
    "```\n",
    "Webcam ‚Üí Frame ‚Üí MTCNN (Ph√°t hi·ªán) ‚Üí Crop Face ‚Üí Resize (160x160) \n",
    "‚Üí FaceNet (Embedding) ‚Üí Cosine Similarity ‚Üí So s√°nh v·ªõi Reference ‚Üí K·∫øt qu·∫£\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
