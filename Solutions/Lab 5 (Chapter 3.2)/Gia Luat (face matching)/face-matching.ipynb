{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e32b23e",
   "metadata": {},
   "source": [
    "# Nháº­n diá»‡n khuÃ´n máº·t thá»i gian thá»±c vá»›i FaceNet & MTCNN trÃªn Webcam\n",
    "\n",
    "BÃ i táº­p thá»±c hÃ nh: XÃ¢y dá»±ng há»‡ thá»‘ng nháº­n diá»‡n khuÃ´n máº·t theo thá»i gian thá»±c sá»­ dá»¥ng:\n",
    "- **MTCNN**: PhÃ¡t hiá»‡n khuÃ´n máº·t\n",
    "- **FaceNet**: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vÃ  so sÃ¡nh khuÃ´n máº·t\n",
    "- **OpenCV**: Truy cáº­p webcam\n",
    "\n",
    "**Äiá»u kiá»‡n so sÃ¡nh:**\n",
    "- Similarity > 0.7: \"Matched\"\n",
    "- Similarity < 0.7: \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82254472",
   "metadata": {},
   "source": [
    "## 1. Import thÆ° viá»‡n vÃ  thiáº¿t láº­p cáº¥u hÃ¬nh\n",
    "\n",
    "Pháº§n nÃ y import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t vÃ  thiáº¿t láº­p cÃ¡c tham sá»‘ quan trá»ng:\n",
    "- **MTCNN**: ThÆ° viá»‡n phÃ¡t hiá»‡n khuÃ´n máº·t vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao\n",
    "- **FaceNet**: MÃ´ hÃ¬nh deep learning Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng khuÃ´n máº·t (embeddings 512 chiá»u)\n",
    "- **OpenCV**: Xá»­ lÃ½ áº£nh vÃ  video\n",
    "\n",
    "**CÃ¡c tham sá»‘ cáº¥u hÃ¬nh:**\n",
    "- `KNOWN_DIR`: ThÆ° má»¥c chá»©a áº£nh cá»§a nhá»¯ng ngÆ°á»i cáº§n nháº­n diá»‡n\n",
    "- `THRESHOLD`: NgÆ°á»¡ng similarity Ä‘á»ƒ xÃ¡c Ä‘á»‹nh \"Matched\" (0.7 = 70% Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng)\n",
    "- `CAM_INDEX`: Chá»‰ sá»‘ webcam (0 = webcam máº·c Ä‘á»‹nh)\n",
    "- `MIN_FACE_SIZE`: KÃ­ch thÆ°á»›c tá»‘i thiá»ƒu cá»§a khuÃ´n máº·t Ä‘Æ°á»£c xá»­ lÃ½ (pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8265fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Applications\\anaconda3\\envs\\KNCVU\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ÄÃ£ import cÃ¡c thÆ° viá»‡n vÃ  thiáº¿t láº­p config\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "KNOWN_DIR = \"known\"          # thÆ° má»¥c chá»©a áº£nh ngÆ°á»i Ä‘Ã£ biáº¿t\n",
    "THRESHOLD = 0.7             # similarity threshold\n",
    "CAM_INDEX = 0               # webcam index (0 thÆ°á»ng lÃ  webcam máº·c Ä‘á»‹nh)\n",
    "MIN_FACE_SIZE = 60          # bá» qua máº·t quÃ¡ nhá» (px)\n",
    "\n",
    "print(\"[OK] ÄÃ£ import cÃ¡c thÆ° viá»‡n vÃ  thiáº¿t láº­p config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be90375",
   "metadata": {},
   "source": [
    "## 2. Äá»‹nh nghÄ©a cÃ¡c hÃ m há»— trá»£ (Helper Functions)\n",
    "\n",
    "CÃ¡c hÃ m tiá»‡n Ã­ch Ä‘á»ƒ xá»­ lÃ½ embeddings vÃ  áº£nh:\n",
    "\n",
    "- **`l2_normalize()`**: Chuáº©n hÃ³a vector theo chuáº©n L2 (Ä‘Æ°a vá» Ä‘á»™ dÃ i = 1)\n",
    "- **`cosine_similarity()`**: TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cosine giá»¯a 2 embeddings (káº¿t quáº£ tá»« -1 Ä‘áº¿n 1, cÃ ng gáº§n 1 = cÃ ng giá»‘ng)\n",
    "- **`preprocess_face()`**: Tiá»n xá»­ lÃ½ khuÃ´n máº·t:\n",
    "  - Chuyá»ƒn tá»« BGR â†’ RGB (OpenCV dÃ¹ng BGR, FaceNet cáº§n RGB)\n",
    "  - Resize vá» 160Ã—160 pixels (kÃ­ch thÆ°á»›c input cá»§a FaceNet)\n",
    "- **`get_embedding()`**: TrÃ­ch xuáº¥t vector Ä‘áº·c trÆ°ng 512 chiá»u tá»« áº£nh khuÃ´n máº·t\n",
    "- **`safe_crop()`**: Crop áº£nh an toÃ n khÃ´ng bá»‹ vÆ°á»£t biÃªn frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d04a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ÄÃ£ Ä‘á»‹nh nghÄ©a cÃ¡c helper functions\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def l2_normalize(x: np.ndarray, eps: float = 1e-10) -> np.ndarray:\n",
    "    \"\"\"Chuáº©n hÃ³a vector theo L2\"\"\"\n",
    "    return x / (np.linalg.norm(x) + eps)\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cosine giá»¯a 2 vectors\"\"\"\n",
    "    a = l2_normalize(a)\n",
    "    b = l2_normalize(b)\n",
    "    return float(np.dot(a, b))\n",
    "\n",
    "def preprocess_face(face_bgr: np.ndarray, target_size=(160, 160)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    FaceNet thÆ°á»ng dÃ¹ng input 160x160, RGB.\n",
    "    Tráº£ vá» máº£ng (160,160,3) RGB uint8.\n",
    "    \"\"\"\n",
    "    face_rgb = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB)\n",
    "    face_rgb = cv2.resize(face_rgb, target_size, interpolation=cv2.INTER_AREA)\n",
    "    return face_rgb\n",
    "\n",
    "def get_embedding(embedder: FaceNet, face_rgb_160: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    keras-facenet: embeddings() nháº­n list/np array áº£nh RGB (uint8 ok).\n",
    "    \"\"\"\n",
    "    emb = embedder.embeddings([face_rgb_160])[0]  # shape (512,)\n",
    "    return emb.astype(np.float32)\n",
    "\n",
    "def safe_crop(frame: np.ndarray, x: int, y: int, w: int, h: int) -> tuple:\n",
    "    \"\"\"Crop an toÃ n, Ä‘áº£m báº£o khÃ´ng vÆ°á»£t biÃªn\"\"\"\n",
    "    H, W = frame.shape[:2]\n",
    "    x1 = max(0, x)\n",
    "    y1 = max(0, y)\n",
    "    x2 = min(W, x + w)\n",
    "    y2 = min(H, y + h)\n",
    "    return frame[y1:y2, x1:x2], (x1, y1, x2, y2)\n",
    "\n",
    "print(\"[OK] ÄÃ£ Ä‘á»‹nh nghÄ©a cÃ¡c helper functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88b5fee",
   "metadata": {},
   "source": [
    "## 3. Khá»Ÿi táº¡o cÃ¡c mÃ´ hÃ¬nh AI\n",
    "\n",
    "Load 2 mÃ´ hÃ¬nh deep learning chÃ­nh:\n",
    "\n",
    "1. **MTCNN (Multi-task Cascaded Convolutional Networks)**:\n",
    "   - PhÃ¡t hiá»‡n khuÃ´n máº·t trong áº£nh/video\n",
    "   - Tráº£ vá» bounding box vÃ  confidence score\n",
    "   - Hoáº¡t Ä‘á»™ng tá»‘t vá»›i nhiá»u khuÃ´n máº·t, gÃ³c nghiÃªng, vÃ  Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng khÃ¡c nhau\n",
    "\n",
    "2. **FaceNet (keras-facenet)**:\n",
    "   - MÃ´ hÃ¬nh CNN pre-trained trÃªn hÃ ng triá»‡u khuÃ´n máº·t\n",
    "   - Chuyá»ƒn Ä‘á»•i áº£nh khuÃ´n máº·t thÃ nh vector 512 chiá»u\n",
    "   - CÃ¡c khuÃ´n máº·t giá»‘ng nhau cÃ³ embeddings gáº§n nhau trong khÃ´ng gian vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28436c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Äang load models...\n",
      "WARNING:tensorflow:From d:\\Applications\\anaconda3\\envs\\KNCVU\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "âœ… MTCNN vÃ  FaceNet Ä‘Ã£ sáºµn sÃ ng!\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# LOAD MODELS\n",
    "# =========================\n",
    "print(\"Äang load models...\")\n",
    "detector = MTCNN()\n",
    "embedder = FaceNet()  # load FaceNet\n",
    "print(\"[OK] MTCNN vÃ  FaceNet Ä‘Ã£ sáºµn sÃ ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7eb51",
   "metadata": {},
   "source": [
    "## 4. XÃ¢y dá»±ng cÆ¡ sá»Ÿ dá»¯ liá»‡u khuÃ´n máº·t (Database)\n",
    "\n",
    "Táº¡o database embeddings tá»« áº£nh trong thÆ° má»¥c `known/`:\n",
    "\n",
    "**Quy trÃ¬nh:**\n",
    "1. Táº¡o thÆ° má»¥c `known/` náº¿u chÆ°a tá»“n táº¡i\n",
    "2. Duyá»‡t qua táº¥t cáº£ file áº£nh (.jpg, .jpeg, .png)\n",
    "3. Vá»›i má»—i áº£nh:\n",
    "   - Äá»c áº£nh vÃ  phÃ¡t hiá»‡n khuÃ´n máº·t báº±ng MTCNN\n",
    "   - Láº¥y khuÃ´n máº·t cÃ³ confidence cao nháº¥t (náº¿u cÃ³ nhiá»u ngÆ°á»i)\n",
    "   - Crop vÃ  preprocess khuÃ´n máº·t\n",
    "   - TrÃ­ch xuáº¥t embedding 512 chiá»u báº±ng FaceNet\n",
    "   - LÆ°u embedding vÃ  tÃªn ngÆ°á»i (tÃªn file khÃ´ng Ä‘uÃ´i) vÃ o arrays\n",
    "4. Chuyá»ƒn sang numpy array Ä‘á»ƒ tÃ­nh toÃ¡n hiá»‡u quáº£\n",
    "\n",
    "**Káº¿t quáº£:** Danh sÃ¡ch `known_embeddings` vÃ  `known_names` Ä‘á»ƒ so sÃ¡nh real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd5189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Äang táº¡o database embeddings tá»« thÆ° má»¥c known/ ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "    + Loaded: gia luat\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "    + Loaded: ronaldo\n",
      "\n",
      "âœ… Database sáºµn sÃ ng: 2 ngÆ°á»i\n",
      "ğŸ“‹ Danh sÃ¡ch: gia luat, ronaldo\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# BUILD KNOWN DATABASE\n",
    "# =========================\n",
    "known_embeddings = []\n",
    "known_names = []\n",
    "\n",
    "# Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³\n",
    "if not os.path.isdir(KNOWN_DIR):\n",
    "    os.makedirs(KNOWN_DIR, exist_ok=True)\n",
    "    print(f\"[!] ÄÃ£ táº¡o thÆ° má»¥c '{KNOWN_DIR}'. HÃ£y bá» áº£nh ngÆ°á»i quen vÃ o Ä‘Ã³ rá»“i cháº¡y láº¡i.\")\n",
    "else:\n",
    "    image_files = [f for f in os.listdir(KNOWN_DIR) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\"[!] ThÆ° má»¥c '{KNOWN_DIR}' chÆ°a cÃ³ áº£nh. HÃ£y thÃªm áº£nh (jpg/png) rá»“i cháº¡y láº¡i.\")\n",
    "    else:\n",
    "        print(f\"[*] Äang táº¡o database embeddings tá»« thÆ° má»¥c {KNOWN_DIR}/ ...\")\n",
    "        \n",
    "        for fn in image_files:\n",
    "            path = os.path.join(KNOWN_DIR, fn)\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                print(f\"[!] KhÃ´ng Ä‘á»c Ä‘Æ°á»£c: {path}\")\n",
    "                continue\n",
    "\n",
    "            # detect face in known image\n",
    "            faces = detector.detect_faces(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            if len(faces) == 0:\n",
    "                print(f\"[!] KhÃ´ng phÃ¡t hiá»‡n máº·t trong: {fn}\")\n",
    "                continue\n",
    "\n",
    "            # láº¥y face cÃ³ confidence cao nháº¥t\n",
    "            faces = sorted(faces, key=lambda d: d.get(\"confidence\", 0), reverse=True)\n",
    "            x, y, w, h = faces[0][\"box\"]\n",
    "            face_crop, _ = safe_crop(img, x, y, w, h)\n",
    "\n",
    "            if face_crop.size == 0 or min(face_crop.shape[:2]) < MIN_FACE_SIZE:\n",
    "                print(f\"[!] Máº·t quÃ¡ nhá»/lá»—i crop trong: {fn}\")\n",
    "                continue\n",
    "\n",
    "            face_160 = preprocess_face(face_crop)\n",
    "            emb = get_embedding(embedder, face_160)\n",
    "\n",
    "            name = os.path.splitext(fn)[0]  # tÃªn = filename khÃ´ng Ä‘uÃ´i\n",
    "            known_embeddings.append(emb)\n",
    "            known_names.append(name)\n",
    "            print(f\"    + Loaded: {name}\")\n",
    "\n",
    "        known_embeddings = np.array(known_embeddings, dtype=np.float32)\n",
    "        \n",
    "        if len(known_embeddings) == 0:\n",
    "            print(\"[!] KhÃ´ng táº¡o Ä‘Æ°á»£c embeddings nÃ o tá»« known/. HÃ£y dÃ¹ng áº£nh rÃµ máº·t hÆ¡n.\")\n",
    "        else:\n",
    "            print(f\"\\n[OK] Database sáºµn sÃ ng: {len(known_embeddings)} ngÆ°á»i\")\n",
    "            print(f\"[INFO] Danh sÃ¡ch: {', '.join(known_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dbdd77",
   "metadata": {},
   "source": [
    "## 5. Nháº­n diá»‡n khuÃ´n máº·t theo thá»i gian thá»±c (Real-time Recognition)\n",
    "\n",
    "Xá»­ lÃ½ video tá»« webcam vÃ  nháº­n diá»‡n khuÃ´n máº·t frame-by-frame:\n",
    "\n",
    "**Luá»“ng xá»­ lÃ½ má»—i frame:**\n",
    "1. Capture frame tá»« webcam vÃ  flip ngang (hiá»‡u á»©ng gÆ°Æ¡ng)\n",
    "2. Chuyá»ƒn sang RGB vÃ  phÃ¡t hiá»‡n khuÃ´n máº·t báº±ng MTCNN\n",
    "3. Vá»›i má»—i khuÃ´n máº·t Ä‘Æ°á»£c phÃ¡t hiá»‡n:\n",
    "   - Kiá»ƒm tra confidence > 0.90 (lá»c detection kÃ©m)\n",
    "   - Crop vÃ  preprocess khuÃ´n máº·t\n",
    "   - TrÃ­ch xuáº¥t embedding\n",
    "   - **So sÃ¡nh vá»›i database**: TÃ­nh cosine similarity vá»›i táº¥t cáº£ known embeddings\n",
    "   - Láº¥y similarity cao nháº¥t vÃ  kiá»ƒm tra threshold:\n",
    "     - **> 0.7**: Matched â†’ váº½ box XANH LÃ + hiá»ƒn thá»‹ tÃªn\n",
    "     - **â‰¤ 0.7**: Unknown â†’ váº½ box Äá»\n",
    "4. Hiá»ƒn thá»‹ frame vá»›i bounding boxes, tÃªn, vÃ  similarity scores\n",
    "5. Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t\n",
    "\n",
    "**Tá»‘i Æ°u:**\n",
    "- Bá» qua khuÃ´n máº·t quÃ¡ nhá» (< 60px)\n",
    "- Hiá»ƒn thá»‹ confidence cá»§a MTCNN\n",
    "- Äáº¿m sá»‘ frames Ä‘Ã£ xá»­ lÃ½\n",
    "\n",
    "**Viá»‡c chá»‰ xá»­ lÃ½ cÃ¡c khuÃ´n máº·t cÃ³ confidence > 0.90 nháº±m:**\n",
    "\n",
    "Loáº¡i bá» cÃ¡c phÃ¡t hiá»‡n kÃ©m chÃ­nh xÃ¡c do nhiá»…u ná»n, Ã¡nh sÃ¡ng yáº¿u hoáº·c váº­t thá»ƒ giá»‘ng khuÃ´n máº·t.\n",
    "\n",
    "Giáº£m sai sá»‘ khi trÃ­ch xuáº¥t embedding: náº¿u vÃ¹ng crop khÃ´ng pháº£i khuÃ´n máº·t tháº­t, FaceNet sáº½ sinh vector Ä‘áº·c trÆ°ng sai lá»‡ch, dáº«n Ä‘áº¿n nháº­n diá»‡n nháº§m.\n",
    "\n",
    "TÄƒng Ä‘á»™ á»•n Ä‘á»‹nh cá»§a há»‡ thá»‘ng realtime, trÃ¡nh viá»‡c nhÃ£n â€œMatched/Unknownâ€ nháº¥p nhÃ¡y liÃªn tá»¥c.\n",
    "\n",
    "Tá»‘i Æ°u hiá»‡u nÄƒng, chá»‰ xá»­ lÃ½ nhá»¯ng khuÃ´n máº·t cÃ³ cháº¥t lÆ°á»£ng tá»‘t, giáº£m táº£i tÃ­nh toÃ¡n khÃ´ng cáº§n thiáº¿t.\n",
    "\n",
    "NgÆ°á»¡ng 0.90 Ä‘Æ°á»£c chá»n dá»±a trÃªn thá»±c nghiá»‡m, Ä‘áº£m báº£o cÃ¢n báº±ng giá»¯a Ä‘á»™ chÃ­nh xÃ¡c phÃ¡t hiá»‡n vÃ  kháº£ nÄƒng nháº­n diá»‡n á»•n Ä‘á»‹nh trong mÃ´i trÆ°á»ng webcam thá»i gian thá»±c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Webcam Ä‘Ã£ sáºµn sÃ ng. Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t.\n",
      "[*] Threshold: 0.7\n",
      "[*] Sá»‘ ngÆ°á»i trong database: 2\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\n",
      "âœ… ÄÃ£ Ä‘Ã³ng webcam vÃ  giáº£i phÃ³ng tÃ i nguyÃªn\n",
      "ğŸ“Š Tá»•ng sá»‘ frames xá»­ lÃ½: 55\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# REALTIME WEBCAM\n",
    "# =========================\n",
    "if len(known_embeddings) == 0:\n",
    "    print(\"[WARNING] KhÃ´ng cÃ³ database Ä‘á»ƒ so sÃ¡nh. HÃ£y thÃªm áº£nh vÃ o thÆ° má»¥c 'known/' trÆ°á»›c!\")\n",
    "else:\n",
    "    cap = cv2.VideoCapture(CAM_INDEX)\n",
    "    if not cap.isOpened():\n",
    "        print(\"[!] KhÃ´ng má»Ÿ Ä‘Æ°á»£c webcam.\")\n",
    "    else:\n",
    "        print(\"[*] Webcam Ä‘Ã£ sáºµn sÃ ng. Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t.\")\n",
    "        print(f\"[*] Threshold: {THRESHOLD}\")\n",
    "        print(f\"[*] Sá»‘ ngÆ°á»i trong database: {len(known_names)}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        frame_count = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Flip frame Ä‘á»ƒ táº¡o hiá»‡u á»©ng gÆ°Æ¡ng\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            detections = detector.detect_faces(rgb)\n",
    "\n",
    "            for det in detections:\n",
    "                conf = det.get(\"confidence\", 0)\n",
    "                if conf < 0.90:  # bá» qua detection cÃ³ confidence tháº¥p\n",
    "                    continue\n",
    "\n",
    "                x, y, w, h = det[\"box\"]\n",
    "                face_crop, (x1, y1, x2, y2) = safe_crop(frame, x, y, w, h)\n",
    "\n",
    "                if face_crop.size == 0:\n",
    "                    continue\n",
    "                if min(face_crop.shape[:2]) < MIN_FACE_SIZE:\n",
    "                    continue\n",
    "\n",
    "                face_160 = preprocess_face(face_crop)\n",
    "                emb_live = get_embedding(embedder, face_160)\n",
    "\n",
    "                # So khá»›p: láº¥y similarity lá»›n nháº¥t\n",
    "                sims = [cosine_similarity(emb_live, e) for e in known_embeddings]\n",
    "                best_idx = int(np.argmax(sims))\n",
    "                best_sim = float(sims[best_idx])\n",
    "                best_name = known_names[best_idx]\n",
    "\n",
    "                # Kiá»ƒm tra threshold\n",
    "                if best_sim > THRESHOLD:\n",
    "                    label = \"Matched\"\n",
    "                    color = (0, 255, 0)  # XANH LÃ\n",
    "                    # display_text = f\"{best_name} | sim={best_sim:.2f}\"  #hiá»ƒn thá»‹ tÃªn\n",
    "                    display_text = f\"MATCHED | sim={best_sim:.2f}\"\n",
    "                else:\n",
    "                    label = \"Unknown\"\n",
    "                    color = (0, 0, 255)  # Äá»\n",
    "                    display_text = f\"UNKNOWN | sim={best_sim:.2f}\"\n",
    "\n",
    "                # Váº½ bounding box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Váº½ background cho text\n",
    "                (tw, th), _ = cv2.getTextSize(display_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                cv2.rectangle(frame, (x1, y1-30), (x1+tw, y1), color, -1)\n",
    "                \n",
    "                # Váº½ text\n",
    "                cv2.putText(frame, display_text, (x1, y1-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                # Váº½ confidence\n",
    "                cv2.putText(frame, f\"Conf: {conf:.2f}\", (x1, y2+20),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n\n",
    "            cv2.putText(frame, \"Press 'q' to quit\", (10, 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # Hiá»ƒn thá»‹ frame\n",
    "            cv2.imshow(\"FaceNet + MTCNN Realtime\", frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\n[OK] ÄÃ£ Ä‘Ã³ng webcam vÃ  giáº£i phÃ³ng tÃ i nguyÃªn\")\n",
    "        print(f\"[INFO] Tá»•ng sá»‘ frames xá»­ lÃ½: {frame_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KNCVU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
